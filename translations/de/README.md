<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "fa4d35e300f7fa5c533131b9eab27e1b",
  "translation_date": "2025-09-29T17:35:30+00:00",
  "source_file": "README.md",
  "language_code": "de"
}
-->
# MCP-Server und PostgreSQL-Beispiel - Analyse des Einzelhandelsumsatzes

## Lernen Sie MCP mit Datenbankintegration durch praktische Beispiele

[![GitHub contributors](https://img.shields.io/github/contributors/microsoft/MCP-Server-and-PostgreSQL-Sample-Retail.svg)](https://GitHub.com/microsoft/MCP-Server-and-PostgreSQL-Sample-Retail/graphs/contributors)
[![GitHub issues](https://img.shields.io/github/issues/microsoft/MCP-Server-and-PostgreSQL-Sample-Retail.svg)](https://GitHub.com/microsoft/MCP-Server-and-PostgreSQL-Sample-Retail/issues)
[![GitHub pull-requests](https://img.shields.io/github/issues-pr/microsoft/MCP-Server-and-PostgreSQL-Sample-Retail.svg)](https://GitHub.com/microsoft/MCP-Server-and-PostgreSQL-Sample-Retail/pulls)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)

[![Join Azure AI Foundry Discord](https://dcbadge.limes.pink/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4)

Folgen Sie diesen Schritten, um mit diesen Ressourcen zu beginnen:

1. **Repository forken**: Klicken Sie [hier, um zu forken](https://github.com/microsoft/MCP-Server-and-PostgreSQL-Sample-Retail/fork)
2. **Repository klonen**: `git clone https://github.com/IHR-BENUTZERNAME/MCP-Server-and-PostgreSQL-Sample-Retail.git`
3. **Treten Sie dem Azure AI Foundry Discord bei**: [Treffen Sie Experten und andere Entwickler](https://discord.com/invite/ByRwuEEgH4)

### üåê Mehrsprachige Unterst√ºtzung

#### Unterst√ºtzt durch GitHub Action (Automatisiert & Immer aktuell)

[Franz√∂sisch](../fr/README.md) | [Spanisch](../es/README.md) | [Deutsch](./README.md) | [Russisch](../ru/README.md) | [Arabisch](../ar/README.md) | [Persisch (Farsi)](../fa/README.md) | [Urdu](../ur/README.md) | [Chinesisch (vereinfacht)](../zh/README.md) | [Chinesisch (traditionell, Macau)](../mo/README.md) | [Chinesisch (traditionell, Hongkong)](../hk/README.md) | [Chinesisch (traditionell, Taiwan)](../tw/README.md) | [Japanisch](../ja/README.md) | [Koreanisch](../ko/README.md) | [Hindi](../hi/README.md) | [Bengalisch](../bn/README.md) | [Marathi](../mr/README.md) | [Nepali](../ne/README.md) | [Punjabi (Gurmukhi)](../pa/README.md) | [Portugiesisch (Portugal)](../pt/README.md) | [Portugiesisch (Brasilien)](../br/README.md) | [Italienisch](../it/README.md) | [Polnisch](../pl/README.md) | [T√ºrkisch](../tr/README.md) | [Griechisch](../el/README.md) | [Thail√§ndisch](../th/README.md) | [Schwedisch](../sv/README.md) | [D√§nisch](../da/README.md) | [Norwegisch](../no/README.md) | [Finnisch](../fi/README.md) | [Niederl√§ndisch](../nl/README.md) | [Hebr√§isch](../he/README.md) | [Vietnamesisch](../vi/README.md) | [Indonesisch](../id/README.md) | [Malaiisch](../ms/README.md) | [Tagalog (Filipino)](../tl/README.md) | [Swahili](../sw/README.md) | [Ungarisch](../hu/README.md) | [Tschechisch](../cs/README.md) | [Slowakisch](../sk/README.md) | [Rum√§nisch](../ro/README.md) | [Bulgarisch](../bg/README.md) | [Serbisch (kyrillisch)](../sr/README.md) | [Kroatisch](../hr/README.md) | [Slowenisch](../sl/README.md) | [Ukrainisch](../uk/README.md) | [Birmanisch (Myanmar)](../my/README.md)

**Falls Sie zus√§tzliche √úbersetzungen w√ºnschen, finden Sie die unterst√ºtzten Sprachen [hier](https://github.com/Azure/co-op-translator/blob/main/getting_started/supported-languages.md)**

## Einf√ºhrung

Dieses Beispiel zeigt, wie man einen umfassenden **Model Context Protocol (MCP)-Server** erstellt und bereitstellt, der KI-Assistenten sicheren und intelligenten Zugriff auf Einzelhandelsumsatzdaten √ºber PostgreSQL bietet. Das Projekt demonstriert Funktionen auf Unternehmensniveau, darunter **Row Level Security (RLS)**, **semantische Suchfunktionen** und **Azure AI-Integration** f√ºr reale Szenarien der Einzelhandelsanalyse.

**Wichtige Anwendungsf√§lle:**
- **KI-gest√ºtzte Verkaufsanalyse**: Erm√∂glichen Sie KI-Assistenten, Einzelhandelsumsatzdaten durch nat√ºrliche Sprache abzufragen und zu analysieren
- **Sicherer Multi-Tenant-Zugriff**: Demonstrieren Sie die Implementierung von Row Level Security, bei der verschiedene Filialleiter nur auf die Daten ihrer eigenen Filiale zugreifen k√∂nnen
- **Semantische Produktsuche**: Zeigen Sie KI-gest√ºtzte Produktsuche mit Text-Embeddings
- **Unternehmensintegration**: Veranschaulichen Sie, wie MCP-Server mit Azure-Diensten und PostgreSQL-Datenbanken integriert werden k√∂nnen

**Ideal f√ºr:**
- Entwickler, die lernen m√∂chten, MCP-Server mit Datenbankintegration zu erstellen
- Dateningenieure, die sichere Multi-Tenant-Analysel√∂sungen implementieren
- KI-Anwendungsentwickler, die mit Einzelhandels- oder E-Commerce-Daten arbeiten
- Alle, die daran interessiert sind, KI-Assistenten mit Unternehmensdatenbanken zu kombinieren

## Treten Sie der Azure AI Foundry Discord Community bei
Teilen Sie Ihre Erfahrungen mit MCP und treffen Sie Experten und Produktgruppen

[![Azure AI Discord](https://dcbadge.limes.pink/api/server/kzRShWzttr)](https://discord.gg/kzRShWzttr)

# MCP-Server f√ºr Verkaufsanalysen

Ein Model Context Protocol (MCP)-Server, der umfassenden Zugriff auf Kundendatenbanken f√ºr das Zava Retail DIY-Gesch√§ft bietet. Dieser Server erm√∂glicht KI-Assistenten, Einzelhandelsumsatzdaten √ºber eine sichere, schema-basierte Schnittstelle abzufragen und zu analysieren.

## üìö Vollst√§ndige Implementierungsanleitung

F√ºr eine detaillierte Aufschl√ºsselung, wie diese L√∂sung erstellt wird und wie √§hnliche MCP-Server implementiert werden k√∂nnen, lesen Sie unsere umfassende **[Beispiel-Durchf√ºhrung](Sample_Walkthrough.md)**. Diese Anleitung bietet:

- **Architektur-Analyse**: Komponentenanalyse und Designmuster
- **Schritt-f√ºr-Schritt-Erstellung**: Von der Projektkonfiguration bis zur Bereitstellung
- **Code-Erkl√§rung**: Detaillierte Beschreibung der MCP-Server-Implementierung
- **Erweiterte Funktionen**: Row Level Security, semantische Suche und √úberwachung
- **Best Practices**: Sicherheits-, Leistungs- und Entwicklungsrichtlinien
- **Fehlerbehebung**: H√§ufige Probleme und L√∂sungen

Ideal f√ºr Entwickler, die die Implementierungsdetails verstehen und √§hnliche L√∂sungen erstellen m√∂chten.

## ü§ñ Was ist MCP (Model Context Protocol)?

**Model Context Protocol (MCP)** ist ein offener Standard, der es KI-Assistenten erm√∂glicht, sicher auf externe Datenquellen und Tools in Echtzeit zuzugreifen. Es fungiert als Br√ºcke, die es KI-Modellen erlaubt, mit Datenbanken, APIs, Dateisystemen und anderen Ressourcen zu interagieren, w√§hrend Sicherheit und Kontrolle gew√§hrleistet bleiben.

### Hauptvorteile:
- **Echtzeit-Datenzugriff**: KI-Assistenten k√∂nnen Live-Datenbanken und APIs abfragen
- **Sichere Integration**: Kontrollierter Zugriff mit Authentifizierung und Berechtigungen  
- **Tool-Erweiterbarkeit**: Benutzerdefinierte Funktionen f√ºr KI-Assistenten hinzuf√ºgen
- **Standardisiertes Protokoll**: Funktioniert plattform√ºbergreifend mit verschiedenen KI-Tools

### Neu bei MCP?

Falls Sie neu beim Model Context Protocol sind, empfehlen wir Ihnen, mit den umfassenden Einsteigerressourcen von Microsoft zu beginnen:

**üìñ [MCP f√ºr Anf√§nger Leitfaden](https://aka.ms/mcp-for-beginners)**

Diese Ressource bietet:
- Einf√ºhrung in MCP-Konzepte und Architektur
- Schritt-f√ºr-Schritt-Tutorials zum Aufbau Ihres ersten MCP-Servers
- Best Practices f√ºr die MCP-Entwicklung
- Integrationsbeispiele mit beliebten KI-Plattformen
- Community-Ressourcen und Unterst√ºtzung

Sobald Sie die Grundlagen verstanden haben, kehren Sie hierher zur√ºck, um diese fortgeschrittene Einzelhandelsanalyse-Implementierung zu erkunden!

## üìö Umfassender Lernleitfaden: /walkthrough

Dieses Repository enth√§lt eine vollst√§ndige **12-Modul-Lern-Durchf√ºhrung**, die dieses MCP-Einzelhandelsserver-Beispiel in leicht verst√§ndliche, schrittweise Lektionen zerlegt. Die Durchf√ºhrung verwandelt dieses funktionierende Beispiel in eine umfassende Bildungsressource, die perfekt f√ºr Entwickler geeignet ist, die lernen m√∂chten, wie man produktionsreife MCP-Server mit Datenbankintegration erstellt.

### Was Sie lernen werden

Die Durchf√ºhrung deckt alles ab, von grundlegenden MCP-Konzepten bis hin zur fortgeschrittenen Produktionsbereitstellung, einschlie√ülich:

- **MCP-Grundlagen**: Verst√§ndnis des Model Context Protocol und seiner realen Anwendungen
- **Datenbankintegration**: Sichere PostgreSQL-Konnektivit√§t mit Row Level Security implementieren
- **KI-gest√ºtzte Funktionen**: Semantische Suchfunktionen mit Azure OpenAI-Embeddings hinzuf√ºgen
- **Sicherheitsimplementierung**: Authentifizierung, Autorisierung und Datenisolierung auf Unternehmensniveau
- **Tool-Entwicklung**: Komplexe MCP-Tools f√ºr Datenanalyse und Business Intelligence erstellen
- **Testen & Debuggen**: Umfassende Teststrategien und Debugging-Techniken
- **VS Code-Integration**: KI-Chat f√ºr nat√ºrliche Sprachdatenbankabfragen konfigurieren
- **Produktionsbereitstellung**: Containerisierung, Skalierung und Cloud-Bereitstellungsstrategien
- **√úberwachung & Beobachtbarkeit**: Application Insights, Logging und Leistungs√ºberwachung

### √úberblick √ºber den Lernpfad

Die Durchf√ºhrung folgt einer progressiven Lernstruktur, die f√ºr Entwickler aller Erfahrungsstufen geeignet ist:

| Modul | Schwerpunkt | Beschreibung | Zeitaufwand |
|-------|-------------|--------------|-------------|
| **[00-Einf√ºhrung](walkthrough/00-Introduction/README.md)** | Grundlagen | MCP-Konzepte, Zava Retail Fallstudie, Architektur√ºberblick | 30 Minuten |
| **[01-Architektur](walkthrough/01-Architecture/README.md)** | Designmuster | Technische Architektur, Schichtendesign, Systemkomponenten | 45 Minuten |
| **[02-Sicherheit](walkthrough/02-Security/README.md)** | Unternehmenssicherheit | Azure-Authentifizierung, Row Level Security, Multi-Tenant-Isolierung | 60 Minuten |
| **[03-Einrichtung](walkthrough/03-Setup/README.md)** | Umgebung | Docker-Einrichtung, Azure CLI, Projektkonfiguration, Validierung | 45 Minuten |
| **[04-Datenbank](walkthrough/04-Database/README.md)** | Datenebene | PostgreSQL-Schema, pgvector, RLS-Richtlinien, Beispieldaten | 60 Minuten |
| **[05-MCP-Server](walkthrough/05-MCP-Server/README.md)** | Kernimplementierung | FastMCP-Framework, Datenbankintegration, Verbindungsmanagement | 90 Minuten |
| **[06-Tools](walkthrough/06-Tools/README.md)** | Tool-Entwicklung | MCP-Tool-Erstellung, Abfragevalidierung, Business Intelligence-Funktionen | 75 Minuten |
| **[07-Semantische-Suche](walkthrough/07-Semantic-Search/README.md)** | KI-Integration | Azure OpenAI-Embeddings, Vektorsuche, hybride Suchstrategien | 60 Minuten |
| **[08-Testen](walkthrough/08-Testing/README.md)** | Qualit√§tssicherung | Unit-Tests, Integrationstests, Leistungstests, Debugging | 75 Minuten |
| **[09-VS-Code](walkthrough/09-VS-Code/README.md)** | Entwicklungserfahrung | VS Code-Konfiguration, KI-Chat-Integration, Debugging-Workflows | 45 Minuten |
| **[10-Bereitstellung](walkthrough/10-Deployment/README.md)** | Produktionsreife | Containerisierung, Azure Container Apps, CI/CD-Pipelines, Skalierung | 90 Minuten |
| **[11-√úberwachung](walkthrough/11-Monitoring/README.md)** | Beobachtbarkeit | Application Insights, strukturiertes Logging, Leistungsmetriken | 60 Minuten |
| **[12-Best-Practices](walkthrough/12-Best-Practices/README.md)** | Produktions-Exzellenz | Sicherheitsoptimierung, Leistungsoptimierung, Unternehmensmuster | 45 Minuten |

**Gesamte Lernzeit**: ~12-15 Stunden umfassendes praktisches Lernen

### üéØ So nutzen Sie die Durchf√ºhrung

**F√ºr Anf√§nger**:
1. Beginnen Sie mit [Modul 00: Einf√ºhrung](walkthrough/00-Introduction/README.md), um MCP-Grundlagen zu verstehen
2. Folgen Sie den Modulen der Reihe nach f√ºr ein vollst√§ndiges Lernerlebnis
3. Jedes Modul baut auf vorherigen Konzepten auf und enth√§lt praktische √úbungen

**F√ºr erfahrene Entwickler**:
1. √úberpr√ºfen Sie die [Haupt√ºbersicht der Durchf√ºhrung](walkthrough/README.md) f√ºr eine Zusammenfassung aller Module
2. Springen Sie zu spezifischen Modulen, die Sie interessieren (z. B. Modul 07 f√ºr KI-Integration)
3. Nutzen Sie einzelne Module als Referenzmaterial f√ºr Ihre eigenen Projekte

**F√ºr Produktionsimplementierung**:
1. Konzentrieren Sie sich auf Module 02 (Sicherheit), 10 (Bereitstellung) und 11 (√úberwachung)
2. √úberpr√ºfen Sie Modul 12 (Best Practices) f√ºr Unternehmensrichtlinien
3. Verwenden Sie die Codebeispiele als produktionsreife Vorlagen

### üöÄ Schnellstart-Optionen

**Option 1: Vollst√§ndiger Lernpfad** (Empfohlen f√ºr Anf√§nger)
```bash
# Clone and start with the introduction
git clone https://github.com/microsoft/MCP-Server-and-PostgreSQL-Sample-Retail.git
cd MCP-Server-and-PostgreSQL-Sample-Retail/walkthrough
# Follow along starting with 00-Introduction/README.md
```

**Option 2: Praktische Implementierung** (Direkt mit dem Aufbau beginnen)
```bash
# Start with setup and build as you learn
cd walkthrough/03-Setup
# Follow the setup guide and continue through implementation modules
```

**Option 3: Produktionsfokus** (Bereitstellung auf Unternehmensebene)
```bash
# Focus on production-ready aspects
# Review modules: 02-Security, 10-Deployment, 11-Monitoring, 12-Best-Practices
```

### üìã Lernvoraussetzungen

**Empfohlener Hintergrund**:
- Grundlegende Erfahrung mit Python-Programmierung
- Vertrautheit mit REST-APIs und Datenbanken
- Allgemeines Verst√§ndnis von KI/ML-Konzepten
- Grundkenntnisse in der Kommandozeile und Docker

**Nicht erforderlich (aber hilfreich)**:
- Vorherige MCP-Erfahrung (wir behandeln dies von Grund auf)
- Erfahrung mit Azure Cloud (wir bieten Schritt-f√ºr-Schritt-Anleitungen)
- Fortgeschrittene PostgreSQL-Kenntnisse (wir erkl√§ren die Konzepte bei Bedarf)

### üí° Lerntipps

1. **Praktischer Ansatz**: Jedes Modul enth√§lt funktionierende Codebeispiele, die Sie ausf√ºhren und anpassen k√∂nnen
2. **Progressive Komplexit√§t**: Die Konzepte bauen sich schrittweise von einfach bis fortgeschritten auf
3. **Praxisbezug**: Alle Beispiele verwenden realistische Szenarien aus dem Einzelhandel
4. **Produktionsreife**: Die Codebeispiele sind f√ºr den tats√§chlichen Einsatz in der Produktion konzipiert
5. **Community-Unterst√ºtzung**: Treten Sie unserer [Discord-Community](https://discord.com/invite/ByRwuEEgH4) bei, um Hilfe und Diskussionen zu erhalten

### üîó Verwandte Ressourcen

- **[MCP f√ºr Anf√§nger](https://aka.ms/mcp-for-beginners)**: Essentielle Hintergrundlekt√ºre
- **[Beispiel-Durchlauf](Sample_Walkthrough.md)**: Technische √úbersicht auf hoher Ebene
- **[Azure AI Foundry](https://azure.microsoft.com/en-us/products/ai-foundry)**: Cloud-Plattform, die in den Beispielen verwendet wird
- **[FastMCP Framework](https://github.com/jlowin/fastmcp)**: Python-Framework f√ºr MCP-Implementierungen

**Bereit zum Lernen?** Beginnen Sie mit **[Modul 00: Einf√ºhrung](walkthrough/00-Introduction/README.md)** oder erkunden Sie die **[komplette √úbersicht des Durchlaufs](walkthrough/README.md)**.

## Voraussetzungen

1. Docker Desktop installiert
2. Git installiert
3. **Azure CLI**: Installieren und authentifizieren Sie sich mit Azure CLI
4. Zugriff auf das OpenAI-Modell `text-embedding-3-small` und optional das Modell `gpt-4o-mini`.

## Erste Schritte

√ñffnen Sie ein Terminalfenster und f√ºhren Sie die folgenden Befehle aus:

1. Authentifizieren Sie sich mit Azure CLI

    ```bash
    az login
    ```

2. Klonen Sie das Repository

    ```bash
    git clone https://github.com/gloveboxes/Zava-MCP-Server-and-PostgreSQL-Sample
    ```

3. Wechseln Sie in das Projektverzeichnis

    ```bash
    cd Zava-MCP-Server-and-PostgreSQL-Sample
    ```

### Azure-Ressourcen bereitstellen

F√ºhren Sie die folgenden Skripte aus, um die Bereitstellung der f√ºr den MCP-Server ben√∂tigten Azure-Ressourcen zu automatisieren.

Die Bereitstellungsskripte stellen automatisch das Modell `text-embedding-3-small` bereit. W√§hrend der Bereitstellung haben Sie die M√∂glichkeit, auch das Modell `gpt-4o-mini` einzuschlie√üen. Beachten Sie, dass `gpt-4o-mini` **nicht erforderlich** f√ºr dieses Projekt ist und nur f√ºr m√∂gliche zuk√ºnftige Erweiterungen enthalten ist.

**W√§hlen Sie das Skript f√ºr Ihre Plattform:**

#### Windows (PowerShell)

```powershell
# Run from the project root directory
cd infra && ./deploy.ps1
```

#### macOS/Linux (Bash)

```bash
# Run from the project root directory
cd infra && ./deploy.sh
```

## MCP-Server ausf√ºhren

Die einfachste M√∂glichkeit, den gesamten Stack (PostgreSQL + MCP-Server) auszuf√ºhren, ist die Verwendung von Docker Compose:

### Stack starten

```bash
# Start PostgreSQL and MCP Server
docker compose up -d

# View logs
docker compose logs -f

# View MCP Server Logs
docker compose logs -f mcp_server

# View the PostgreSQL Logs
docker compose logs -f pg17

# Stop the stack
docker compose down -v
```

## Nutzung

Die folgenden Schritte gehen davon aus, dass Sie die integrierte VS Code-Unterst√ºtzung f√ºr den MCP-Server verwenden.

1. √ñffnen Sie das Projekt in VS Code. F√ºhren Sie im Terminal aus:

    ```bash
    code .
    ```

2. Starten Sie einen oder mehrere MCP-Server mit den Konfigurationen in `.vscode/mcp.json`. Die Datei enth√§lt vier verschiedene Serverkonfigurationen, die jeweils eine andere Rolle eines Filialleiters darstellen:

   - Jede Konfiguration verwendet eine eindeutige RLS (Row Level Security)-Benutzer-ID
   - Diese Benutzer-IDs simulieren verschiedene Identit√§ten von Filialleitern, die auf die Datenbank zugreifen
   - Das RLS-System beschr√§nkt den Datenzugriff basierend auf dem zugewiesenen Standort des Filialleiters
   - Dies spiegelt reale Szenarien wider, in denen sich Filialleiter mit unterschiedlichen Entra-ID-Konten anmelden

    ```json
    {
        "servers": {
            "zava-sales-analysis-headoffice": {
                "url": "http://127.0.0.1:8000/mcp",
                "type": "http",
                "headers": {"x-rls-user-id": "00000000-0000-0000-0000-000000000000"}
            },
            "zava-sales-analysis-seattle": {
                "url": "http://127.0.0.1:8000/mcp",
                "type": "http",
                "headers": {"x-rls-user-id": "f47ac10b-58cc-4372-a567-0e02b2c3d479"}
            },
            "zava-sales-analysis-redmond": {
                "url": "http://127.0.0.1:8000/mcp",
                "type": "http",
                "headers": {"x-rls-user-id": "e7f8a9b0-c1d2-3e4f-5678-90abcdef1234"}
            },
            "zava-sales-analysis-online": {
                "url": "http://127.0.0.1:8000/mcp",
                "type": "http",
                "headers": {"x-rls-user-id": "2f4e6d8c-1a3b-5c7e-9f0a-b2d4f6e8c0a2"}
            }
        },
        "inputs": []
    }
    ```

### VS Code AI Chat √∂ffnen

1. √ñffnen Sie den AI-Chat-Modus in VS Code
2. Geben Sie **#zava** ein und w√§hlen Sie einen der gestarteten MCP-Server aus
3. Stellen Sie Fragen zu den Verkaufsdaten ‚Äì siehe Beispielanfragen unten

### Beispielanfragen

1. Zeige die Top 20 Produkte nach Umsatz
1. Zeige Verk√§ufe nach Filiale
1. Wie waren die Verk√§ufe des letzten Quartals nach Kategorie?
1. Welche Produkte verkaufen wir, die "Beh√§ltern f√ºr Farbe" √§hneln?

## Funktionen

- **Zugriff auf mehrere Tabellen-Schemata**: Abrufen von Schemata f√ºr mehrere Datenbanktabellen in einer einzigen Anfrage
- **Sichere Abfrageausf√ºhrung**: Ausf√ºhren von PostgreSQL-Abfragen mit Unterst√ºtzung f√ºr Row Level Security (RLS)
- **Echtzeitdaten**: Zugriff auf aktuelle Verkaufs-, Bestands- und Kundendaten
- **Datum-/Zeit-Werkzeuge**: Abrufen aktueller UTC-Zeitstempel f√ºr zeitkritische Analysen
- **Flexible Bereitstellung**: Unterst√ºtzt HTTP-Server-Modus

## Unterst√ºtzte Tabellen

Der Server bietet Zugriff auf die folgenden Datenbanktabellen des Einzelhandels:

- `retail.customers` - Kundeninformationen und Profile
- `retail.stores` - Filialstandorte und Details
- `retail.categories` - Produktkategorien und Hierarchien
- `retail.product_types` - Klassifikationen von Produkttypen
- `retail.products` - Produktkatalog und Spezifikationen
- `retail.orders` - Kundenbestellungen und Transaktionen
- `retail.order_items` - Einzelne Artikel innerhalb von Bestellungen
- `retail.inventory` - Aktuelle Bestandsdaten und Lagerbest√§nde

## Verf√ºgbare Werkzeuge

### `get_multiple_table_schemas`

Abrufen von Datenbankschemata f√ºr mehrere Tabellen in einer einzigen Anfrage.

**Parameter:**

- `table_names` (list[str]): Liste g√ºltiger Tabellennamen aus den oben unterst√ºtzten Tabellen

**R√ºckgabe:** Zusammengef√ºgte Schema-Strings f√ºr die angeforderten Tabellen

### `execute_sales_query`

Ausf√ºhren von PostgreSQL-Abfragen gegen die Verkaufsdatenbank mit Row Level Security.

**Parameter:**

- `postgresql_query` (str): Eine korrekt formulierte PostgreSQL-Abfrage

**R√ºckgabe:** Abfrageergebnisse, formatiert als String (auf 20 Zeilen begrenzt f√ºr bessere Lesbarkeit)

**Best Practices:**

- Rufen Sie immer zuerst die Tabellenschemata ab
- Verwenden Sie exakte Spaltennamen aus den Schemata
- Verbinden Sie verwandte Tabellen f√ºr umfassende Analysen
- Aggregieren Sie Ergebnisse, wenn angemessen
- Begrenzen Sie die Ausgabe f√ºr bessere Lesbarkeit

### `get_current_utc_date`

Abrufen des aktuellen UTC-Datums und der Uhrzeit im ISO-Format.

**R√ºckgabe:** Aktuelles UTC-Datum/Uhrzeit im ISO-Format (YYYY-MM-DDTHH:MM:SS.fffffZ)

### `semantic_search_products`

Durchf√ºhren einer semantischen Suche nach Produkten basierend auf Benutzeranfragen.

**R√ºckgabe:** Eine Liste von Produkten, die den Suchkriterien entsprechen

**Parameter:**

- `query` (str): Die Suchanfrage als String

**R√ºckgabe:** Eine Liste von Produkten, die den Suchkriterien entsprechen

## Sicherheitsfunktionen

### Row Level Security (RLS)

Der Server implementiert Row Level Security, um sicherzustellen, dass Benutzer nur auf Daten zugreifen, zu denen sie berechtigt sind:

- **HTTP-Modus**: Verwendet den Header `x-rls-user-id`, um den anfragenden Benutzer zu identifizieren

- **Standard-Fallback**: Verwendet eine Platzhalter-UUID, wenn keine Benutzer-ID angegeben ist

#### Filialspezifische RLS-Benutzer-IDs

Jeder Standort von Zava Retail hat eine eindeutige RLS-Benutzer-ID, die bestimmt, auf welche Daten der Benutzer zugreifen kann:

| Filialstandort | RLS-Benutzer-ID | Beschreibung |
|----------------|-----------------|--------------|
| **Globaler Zugriff** | `00000000-0000-0000-0000-000000000000` | Standard-Fallback ‚Äì Zugriff auf alle Filialen |
| **Seattle** | `f47ac10b-58cc-4372-a567-0e02b2c3d479` | Daten der Zava Retail-Filiale in Seattle |
| **Bellevue** | `6ba7b810-9dad-11d1-80b4-00c04fd430c8` | Daten der Zava Retail-Filiale in Bellevue |
| **Tacoma** | `a1b2c3d4-e5f6-7890-abcd-ef1234567890` | Daten der Zava Retail-Filiale in Tacoma |
| **Spokane** | `d8e9f0a1-b2c3-4567-8901-234567890abc` | Daten der Zava Retail-Filiale in Spokane |
| **Everett** | `3b9ac9fa-cd5e-4b92-a7f2-b8c1d0e9f2a3` | Daten der Zava Retail-Filiale in Everett |
| **Redmond** | `e7f8a9b0-c1d2-3e4f-5678-90abcdef1234` | Daten der Zava Retail-Filiale in Redmond |
| **Kirkland** | `9c8b7a65-4321-fed0-9876-543210fedcba` | Daten der Zava Retail-Filiale in Kirkland |
| **Online** | `2f4e6d8c-1a3b-5c7e-9f0a-b2d4f6e8c0a2` | Daten des Zava Retail-Online-Shops |

#### RLS-Implementierung

Wenn sich ein Benutzer mit der spezifischen RLS-Benutzer-ID einer Filiale verbindet, sieht er nur:

- Kunden, die mit dieser Filiale verbunden sind
- Bestellungen, die an diesem Standort aufgegeben wurden
- Bestandsdaten f√ºr diese spezifische Filiale
- Filialspezifische Verkaufs- und Leistungskennzahlen

Dies gew√§hrleistet die Datenisolierung zwischen verschiedenen Filialstandorten, w√§hrend ein einheitliches Datenbankschema beibehalten wird.

## Architektur

### Anwendungskontext

Der Server verwendet einen verwalteten Anwendungskontext mit:

- **Datenbank-Verbindungspool**: Effizientes Verbindungsmanagement f√ºr den HTTP-Modus
- **Lebenszyklus-Management**: Ordnungsgem√§√üe Ressourcenbereinigung beim Herunterfahren
- **Typensicherheit**: Stark typisierter Kontext mit der `AppContext`-Dataclass

### Anfragekontext

- **Header-Extraktion**: Sichere Header-Analyse zur Benutzeridentifikation
- **RLS-Integration**: Automatische Benutzer-ID-Aufl√∂sung aus dem Anfragekontext
- **Fehlerbehandlung**: Umfassende Fehlerbehandlung mit benutzerfreundlichen Nachrichten

## Datenbankintegration

Der Server integriert sich mit einer PostgreSQL-Datenbank √ºber die Klasse `PostgreSQLSchemaProvider`:

- **Verbindungspooling**: Verwendet asynchrone Verbindungspools f√ºr Skalierbarkeit
- **Schema-Metadaten**: Bietet detaillierte Informationen zu Tabellenschemata
- **Abfrageausf√ºhrung**: Sichere Abfrageausf√ºhrung mit RLS-Unterst√ºtzung
- **Ressourcenmanagement**: Automatische Bereinigung von Datenbankressourcen

## Fehlerbehandlung

Der Server implementiert eine robuste Fehlerbehandlung:

- **Tabellenvalidierung**: Stellt sicher, dass nur g√ºltige Tabellennamen abgerufen werden
- **Abfragevalidierung**: Validiert PostgreSQL-Abfragen vor der Ausf√ºhrung
- **Ressourcenmanagement**: Ordnungsgem√§√üe Bereinigung auch bei Fehlern
- **Benutzerfreundliche Nachrichten**: Klare Fehlermeldungen zur Fehlerbehebung

## Sicherheits√ºberlegungen

1. **Row Level Security**: Alle Abfragen respektieren RLS-Richtlinien basierend auf der Benutzeridentit√§t
2. **Datenisolierung der Filialen**: Jede Filiale hat eine eigene RLS-Benutzer-ID, die nur Zugriff auf die Daten dieser Filiale gew√§hrt
3. **Eingabevalidierung**: Tabellennamen und Abfragen werden vor der Ausf√ºhrung validiert
4. **Ressourcenbegrenzung**: Abfrageergebnisse sind begrenzt, um √ºberm√§√üige Ressourcennutzung zu verhindern
5. **Verbindungssicherheit**: Verwendet sichere Datenbankverbindungspraktiken
6. **Benutzeridentit√§tspr√ºfung**: Stellt sicher, dass die korrekte RLS-Benutzer-ID f√ºr die beabsichtigte Filiale verwendet wird

### Wichtige Sicherheitshinweise

- **Verwenden Sie niemals Produktions-RLS-Benutzer-IDs in Entwicklungsumgebungen**
- **√úberpr√ºfen Sie immer, ob die RLS-Benutzer-ID mit der beabsichtigten Filiale √ºbereinstimmt, bevor Sie Abfragen ausf√ºhren**
- **Die Standard-UUID (`00000000-0000-0000-0000-000000000000`) bietet eingeschr√§nkten Zugriff**
- **Jeder Filialleiter sollte nur Zugriff auf die RLS-Benutzer-ID seiner Filiale haben**

## Entwicklung

### Projektstruktur

```text
mcp_server/
‚îú‚îÄ‚îÄ sales_analysis.py          # Main MCP server implementation
‚îú‚îÄ‚îÄ sales_analysis_postgres.py # PostgreSQL integration layer
‚îú‚îÄ‚îÄ sales_analysis_text_embedding.py # Text embedding for semantic search tool
```

### Schl√ºsselkomponenten

- **FastMCP-Server**: Moderne MCP-Server-Implementierung mit asynchroner Unterst√ºtzung
- **PostgreSQL-Provider**: Datenbank-Abstraktionsschicht mit RLS-Unterst√ºtzung
- **Kontextmanagement**: Typensicheres Handling von Anwendungs- und Anfragekontexten
- **Werkzeugregistrierung**: Deklarative Werkzeugregistrierung mit Pydantic-Validierung

## Beitrag leisten

Wenn Sie zu diesem Server beitragen:

1. Stellen Sie sicher, dass alle Datenbankabfragen Row Level Security respektieren
2. F√ºgen Sie eine ordnungsgem√§√üe Fehlerbehandlung f√ºr neue Werkzeuge hinzu
3. Aktualisieren Sie diese README-Datei mit neuen Funktionen oder √Ñnderungen
4. Testen Sie den HTTP-Server-Modus
5. Validieren Sie Eingabeparameter und bieten Sie klare Fehlermeldungen

## [Lizenz](https://github.com/microsoft/MCP-Server-and-PostgreSQL-Sample-Retail/blob/main/LICENSE)

---

*Dieser MCP-Server erm√∂glicht sicheren, effizienten Zugriff auf Verkaufsdaten von Zava Retail f√ºr KI-gest√ºtzte Analysen und Einblicke.*

---

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser √úbersetzung ergeben.