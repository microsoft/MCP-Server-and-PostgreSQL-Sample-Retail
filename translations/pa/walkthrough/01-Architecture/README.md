<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "907b008a90c728fd33a1c0f66889e8e2",
  "translation_date": "2025-09-29T20:47:05+00:00",
  "source_file": "walkthrough/01-Architecture/README.md",
  "language_code": "pa"
}
-->
# ‡®ï‡©ã‡®∞ ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞ ‡®∏‡©∞‡®ï‡®≤‡®™

## üéØ ‡®á‡®π ‡®Æ‡©ã‡®°‡®ø‡®ä‡®≤ ‡®ï‡©Ä ‡®ï‡®µ‡®∞ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à

‡®á‡®π ‡®Æ‡©ã‡®°‡®ø‡®ä‡®≤ MCP ‡®∏‡®∞‡®µ‡®∞ ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞ ‡®™‡©à‡®ü‡®∞‡®®, ‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®°‡®ø‡®ú‡®º‡®æ‡®à‡®® ‡®∏‡®ø‡®ß‡®æ‡®Ç‡®§‡®æ‡®Ç, ‡®Ö‡®§‡©á ‡®§‡®ï‡®®‡©Ä‡®ï‡©Ä ‡®Ö‡®Æ‡®≤ ‡®∞‡®£‡®®‡©Ä‡®§‡©Ä‡®Ü‡®Ç ‡®¶‡®æ ‡®µ‡®ø‡®∏‡®§‡©ç‡®∞‡®ø‡®§ ‡®Ö‡®ß‡®ø‡®ê‡®® ‡®™‡©ç‡®∞‡®¶‡®æ‡®® ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à ‡®ú‡©ã ‡®Æ‡®ú‡®º‡®¨‡©Ç‡®§, ‡®∏‡®ï‡©á‡®≤ ‡®ï‡®∞‡®® ‡®Ø‡©ã‡®ó ‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏-‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®ü‡®° AI ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®®‡©Ç‡©∞ ‡®∏‡®º‡®ï‡®§‡©Ä ‡®¶‡®ø‡©∞‡®¶‡©á ‡®π‡®®‡•§

## ‡®ù‡®≤‡®ï

‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®® ‡®®‡®æ‡®≤ ‡®á‡©±‡®ï ‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®®-‡®§‡®ø‡®Ü‡®∞ MCP ‡®∏‡®∞‡®µ‡®∞ ‡®¨‡®£‡®æ‡®â‡®£ ‡®≤‡®à ‡®ß‡®ø‡®Ü‡®®‡®™‡©Ç‡®∞‡®µ‡®ï ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞ ‡®´‡©à‡®∏‡®≤‡©á ‡®≤‡©à‡®£‡©á ‡®≤‡®æ‡®ú‡®º‡®Æ‡©Ä ‡®π‡®®‡•§ ‡®á‡®π ‡®Æ‡©ã‡®°‡®ø‡®ä‡®≤ ‡®∏‡®æ‡®°‡©á Zava Retail ‡®ê‡®®‡®æ‡®≤‡®ø‡®ü‡®ø‡®ï‡®∏ ‡®π‡©±‡®≤ ‡®®‡©Ç‡©∞ ‡®Æ‡®ú‡®º‡®¨‡©Ç‡®§, ‡®∏‡©Å‡®∞‡©±‡®ñ‡®ø‡®Ö‡®§, ‡®Ö‡®§‡©á ‡®∏‡®ï‡©á‡®≤ ‡®ï‡®∞‡®® ‡®Ø‡©ã‡®ó ‡®¨‡®£‡®æ‡®â‡®£ ‡®µ‡®æ‡®≤‡©á ‡®Æ‡©Å‡©±‡®ñ ‡®π‡®ø‡©±‡®∏‡®ø‡®Ü‡®Ç, ‡®°‡®ø‡®ú‡®º‡®æ‡®à‡®® ‡®™‡©à‡®ü‡®∞‡®®, ‡®Ö‡®§‡©á ‡®§‡®ï‡®®‡©Ä‡®ï‡©Ä ‡®µ‡®ø‡®ö‡®æ‡®∞‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®§‡©ã‡©ú ‡®ï‡©á ‡®∏‡®Æ‡®ù‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à‡•§

‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ ‡®∏‡®Æ‡®ù ‡®Ü‡®µ‡©á‡®ó‡©Ä ‡®ï‡®ø ‡®π‡®∞ ‡®≤‡©á‡®Ö‡®∞ ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®á‡©∞‡®ü‡®∞‡©à‡®ï‡®ü ‡®ï‡®∞‡®¶‡©Ä ‡®π‡©à, ‡®ï‡®ø‡®â‡®Ç ‡®ñ‡®æ‡®∏ ‡®§‡®ï‡®®‡®æ‡®≤‡©ã‡®ú‡©Ä‡®Ü‡®Ç ‡®¶‡©Ä ‡®ö‡©ã‡®£ ‡®ï‡©Ä‡®§‡©Ä ‡®ó‡®à, ‡®Ö‡®§‡©á ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®á‡®π ‡®™‡©à‡®ü‡®∞‡®® ‡®Ü‡®™‡®£‡©á MCP ‡®Ö‡®Æ‡®≤‡®æ‡®Ç '‡®§‡©á ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡®∞‡®®‡©á ‡®π‡®®‡•§

## ‡®∏‡®ø‡©±‡®ñ‡®£ ‡®¶‡©á ‡®â‡®¶‡©á‡®∏‡®º

‡®á‡®∏ ‡®Æ‡©ã‡®°‡®ø‡®ä‡®≤ ‡®¶‡©á ‡®Ö‡©∞‡®§ ‡®§‡©±‡®ï, ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®∏‡®Æ‡®∞‡©±‡®• ‡®π‡©ã‡®µ‡©ã‡®ó‡©á:

- **‡®µ‡®ø‡®∏‡®º‡®≤‡©á‡®∏‡®º‡®£** ‡®ï‡®∞‡©ã: ‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®® ‡®®‡®æ‡®≤ ‡®á‡©±‡®ï MCP ‡®∏‡®∞‡®µ‡®∞ ‡®¶‡©Ä ‡®≤‡©á‡®Ö‡®∞‡®° ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞  
- **‡®∏‡®Æ‡®ù‡©ã**: ‡®π‡®∞ ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞ ‡®π‡®ø‡©±‡®∏‡©á ‡®¶‡©Ä ‡®≠‡©Ç‡®Æ‡®ø‡®ï‡®æ ‡®Ö‡®§‡©á ‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞‡©Ä‡®Ü‡®Ç  
- **‡®°‡®ø‡®ú‡®º‡®æ‡®à‡®®** ‡®ï‡®∞‡©ã: ‡®Æ‡®≤‡®ü‡©Ä-‡®ü‡©à‡®®‡©à‡®Ç‡®ü MCP ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®®‡©Ç‡©∞ ‡®∏‡®π‡®æ‡®á‡®ï ‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®∏‡®ï‡©Ä‡®Æ‡®æ‡®Ç  
- **‡®Ö‡®Æ‡®≤** ‡®ï‡®∞‡©ã: ‡®ï‡®®‡©à‡®ï‡®∏‡®º‡®® ‡®™‡©Ç‡®≤‡®ø‡©∞‡®ó ‡®Ö‡®§‡©á ‡®∏‡®∞‡©ã‡®§ ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®® ‡®∞‡®£‡®®‡©Ä‡®§‡©Ä‡®Ü‡®Ç  
- **‡®≤‡®æ‡®ó‡©Ç** ‡®ï‡®∞‡©ã: ‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®® ‡®∏‡®ø‡®∏‡®ü‡®Æ ‡®≤‡®à ‡®ê‡®∞‡®∞ ‡®π‡©à‡®Ç‡®°‡®≤‡®ø‡©∞‡®ó ‡®Ö‡®§‡©á ‡®≤‡©å‡®ó‡®ø‡©∞‡®ó ‡®™‡©à‡®ü‡®∞‡®®  
- **‡®Æ‡©Å‡®≤‡®æ‡®Ç‡®ï‡®£** ‡®ï‡®∞‡©ã: ‡®µ‡©±‡®ñ-‡®µ‡©±‡®ñ ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞ ‡®™‡®π‡©Å‡©∞‡®ö‡®æ‡®Ç ‡®¶‡©á ‡®´‡®æ‡®á‡®¶‡©á ‡®Ö‡®§‡©á ‡®®‡©Å‡®ï‡®∏‡®æ‡®®  

## üèóÔ∏è MCP ‡®∏‡®∞‡®µ‡®∞ ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞ ‡®≤‡©á‡®Ö‡®∞

‡®∏‡®æ‡®°‡®æ MCP ‡®∏‡®∞‡®µ‡®∞ **‡®≤‡©á‡®Ö‡®∞‡®° ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞** ‡®®‡©Ç‡©∞ ‡®Ö‡®Æ‡®≤ ‡®µ‡®ø‡©±‡®ö ‡®≤‡®ø‡®Ü‡®â‡®Ç‡®¶‡®æ ‡®π‡©à ‡®ú‡©ã ‡®ö‡®ø‡©∞‡®§‡®æ‡®µ‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®µ‡©±‡®ñ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à ‡®Ö‡®§‡©á ‡®∞‡©±‡®ñ-‡®∞‡®ñ‡®æ‡®Ö ‡®®‡©Ç‡©∞ ‡®â‡®§‡®∏‡®º‡®æ‡®π‡®ø‡®§ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à:

### ‡®≤‡©á‡®Ö‡®∞ 1: ‡®™‡©ç‡®∞‡©ã‡®ü‡©ã‡®ï‡©ã‡®≤ ‡®≤‡©á‡®Ö‡®∞ (FastMCP)
**‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞‡©Ä**: MCP ‡®™‡©ç‡®∞‡©ã‡®ü‡©ã‡®ï‡©ã‡®≤ ‡®∏‡©∞‡®ö‡®æ‡®∞ ‡®Ö‡®§‡©á ‡®∏‡©Å‡®®‡©á‡®π‡®æ ‡®∞‡©Ç‡®ü‡®ø‡©∞‡®ó ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®≠‡®æ‡®≤‡®£‡®æ

```python
# FastMCP server setup
from fastmcp import FastMCP

mcp = FastMCP("Zava Retail Analytics")

# Tool registration with type safety
@mcp.tool()
async def execute_sales_query(
    ctx: Context,
    postgresql_query: Annotated[str, Field(description="Well-formed PostgreSQL query")]
) -> str:
    """Execute PostgreSQL queries with Row Level Security."""
    return await query_executor.execute(postgresql_query, ctx)
```

**‡®Æ‡©Å‡©±‡®ñ ‡®µ‡®ø‡®∏‡®º‡©á‡®∏‡®º‡®§‡®æ‡®µ‡®æ‡®Ç**:
- **‡®™‡©ç‡®∞‡©ã‡®ü‡©ã‡®ï‡©ã‡®≤ ‡®Ö‡®®‡©Å‡®ï‡©Ç‡®≤‡®§‡®æ**: ‡®™‡©Ç‡®∞‡©Ä MCP ‡®µ‡®ø‡®∏‡®º‡©á‡®∏‡®º‡®§‡®æ ‡®∏‡®π‡®æ‡®á‡®§‡®æ  
- **‡®ü‡®æ‡®à‡®™ ‡®∏‡©á‡®´‡®ü‡©Ä**: ‡®∞‡®ø‡®ï‡®µ‡©à‡®∏‡®ü/‡®∞‡®ø‡®∏‡®™‡®æ‡®Ç‡®∏ ‡®µ‡©à‡®∞‡©Ä‡®´‡®ø‡®ï‡©á‡®∏‡®º‡®® ‡®≤‡®à Pydantic ‡®Æ‡®æ‡®°‡®≤  
- **‡®ê‡®∏‡®ø‡©∞‡®ï ‡®∏‡®π‡®æ‡®á‡®§‡®æ**: ‡®â‡©±‡®ö ‡®∏‡®Æ‡®ï‡®æ‡®≤‡©Ä‡®§‡®æ ‡®≤‡®à ‡®®‡®æ‡®®-‡®¨‡®≤‡®æ‡®ï‡®ø‡©∞‡®ó I/O  
- **‡®ê‡®∞‡®∞ ‡®π‡©à‡®Ç‡®°‡®≤‡®ø‡©∞‡®ó**: ‡®Æ‡®ø‡®Ü‡®∞‡©Ä‡®ï‡©ç‡®∞‡®ø‡®§ ‡®ê‡®∞‡®∞ ‡®ú‡®µ‡®æ‡®¨  

### ‡®≤‡©á‡®Ö‡®∞ 2: ‡®¨‡®ø‡®ú‡®º‡®®‡®∏ ‡®≤‡®æ‡®ú‡®ø‡®ï ‡®≤‡©á‡®Ö‡®∞
**‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞‡©Ä**: ‡®¨‡®ø‡®ú‡®º‡®®‡®∏ ‡®®‡®ø‡®Ø‡®Æ‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Ö‡®Æ‡®≤ ‡®µ‡®ø‡©±‡®ö ‡®≤‡®ø‡®Ü‡®â‡®£‡®æ ‡®Ö‡®§‡©á ‡®™‡©ç‡®∞‡©ã‡®ü‡©ã‡®ï‡©ã‡®≤ ‡®Ö‡®§‡©á ‡®°‡®æ‡®ü‡®æ ‡®≤‡©á‡®Ö‡®∞ ‡®¶‡©á ‡®µ‡®ø‡®ö‡®ï‡®æ‡®∞ ‡®∏‡®π‡®ø‡®ï‡®æ‡®∞ ‡®ï‡®∞‡®®‡®æ

```python
class SalesAnalyticsService:
    """Business logic for retail analytics operations."""
    
    async def get_store_performance(
        self, 
        store_id: str, 
        time_period: str
    ) -> Dict[str, Any]:
        """Calculate store performance metrics."""
        
        # Validate business rules
        if not self._validate_store_access(store_id):
            raise UnauthorizedError("Access denied for store")
        
        # Coordinate data retrieval
        sales_data = await self.db_provider.get_sales_data(store_id, time_period)
        metrics = self._calculate_metrics(sales_data)
        
        return {
            "store_id": store_id,
            "period": time_period,
            "metrics": metrics,
            "insights": self._generate_insights(metrics)
        }
```

**‡®Æ‡©Å‡©±‡®ñ ‡®µ‡®ø‡®∏‡®º‡©á‡®∏‡®º‡®§‡®æ‡®µ‡®æ‡®Ç**:
- **‡®¨‡®ø‡®ú‡®º‡®®‡®∏ ‡®®‡®ø‡®Ø‡®Æ ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡®∞‡®®‡®æ**: ‡®∏‡®ü‡©ã‡®∞ ‡®ê‡®ï‡®∏‡©à‡®∏ ‡®µ‡©à‡®∞‡©Ä‡®´‡®ø‡®ï‡©á‡®∏‡®º‡®® ‡®Ö‡®§‡©á ‡®°‡®æ‡®ü‡®æ ‡®¶‡©Ä ‡®∏‡©±‡®ö‡®æ‡®à  
- **‡®∏‡©á‡®µ‡®æ ‡®∏‡®π‡®ø‡®ï‡®æ‡®∞**: ‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®Ö‡®§‡©á AI ‡®∏‡©á‡®µ‡®æ‡®µ‡®æ‡®Ç ‡®¶‡©á ‡®µ‡®ø‡®ö‡®ï‡®æ‡®∞ ‡®∏‡®Æ‡®∞‡®•‡®®  
- **‡®°‡®æ‡®ü‡®æ ‡®∞‡©Ç‡®™‡®æ‡®Ç‡®§‡®∞‡®®**: ‡®ï‡©±‡®ö‡©á ‡®°‡®æ‡®ü‡®æ ‡®®‡©Ç‡©∞ ‡®¨‡®ø‡®ú‡®º‡®®‡®∏ ‡®Ö‡©∞‡®§‡®∞‡®¶‡©ç‡®∞‡®ø‡®∏‡®º‡®ü‡©Ä ‡®µ‡®ø‡©±‡®ö ‡®¨‡®¶‡®≤‡®£‡®æ  
- **‡®ï‡©à‡®∏‡®º‡®ø‡©∞‡®ó ‡®∞‡®£‡®®‡©Ä‡®§‡©Ä**: ‡®µ‡®æ‡®∞‡©∞-‡®µ‡®æ‡®∞ ‡®™‡©Å‡©±‡®õ‡©á ‡®ú‡®æ‡®£ ‡®µ‡®æ‡®≤‡©á ‡®™‡©ç‡®∞‡®∏‡®º‡®®‡®æ‡®Ç ‡®≤‡®à ‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®® ‡®¶‡®æ ‡®Ö‡®ß‡®ø‡®ï‡®§‡®Æ  

### ‡®≤‡©á‡®Ö‡®∞ 3: ‡®°‡®æ‡®ü‡®æ ‡®ê‡®ï‡®∏‡©à‡®∏ ‡®≤‡©á‡®Ö‡®∞
**‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞‡©Ä**: ‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®ï‡®®‡©à‡®ï‡®∏‡®º‡®®, ‡®™‡©Å‡©±‡®õ‡®ó‡®ø‡©±‡®õ ‡®Ö‡®Æ‡®≤, ‡®Ö‡®§‡©á ‡®°‡®æ‡®ü‡®æ ‡®Æ‡©à‡®™‡®ø‡©∞‡®ó ‡®¶‡®æ ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®®

```python
class PostgreSQLProvider:
    """Data access layer for PostgreSQL operations."""
    
    def __init__(self, connection_config: Dict[str, Any]):
        self.connection_pool: Optional[Pool] = None
        self.config = connection_config
    
    async def execute_query(
        self, 
        query: str, 
        rls_user_id: str
    ) -> List[Dict[str, Any]]:
        """Execute query with RLS context."""
        
        async with self.connection_pool.acquire() as conn:
            # Set RLS context
            await conn.execute(
                "SELECT set_config('app.current_rls_user_id', $1, false)",
                rls_user_id
            )
            
            # Execute query with timeout
            try:
                rows = await asyncio.wait_for(
                    conn.fetch(query),
                    timeout=30.0
                )
                return [dict(row) for row in rows]
            except asyncio.TimeoutError:
                raise QueryTimeoutError("Query execution exceeded timeout")
```

**‡®Æ‡©Å‡©±‡®ñ ‡®µ‡®ø‡®∏‡®º‡©á‡®∏‡®º‡®§‡®æ‡®µ‡®æ‡®Ç**:
- **‡®ï‡®®‡©à‡®ï‡®∏‡®º‡®® ‡®™‡©Ç‡®≤‡®ø‡©∞‡®ó**: ‡®∏‡®∞‡©ã‡®§‡®æ‡®Ç ‡®¶‡®æ ‡®ï‡©Å‡®∏‡®º‡®≤ ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®®  
- **‡®ü‡©ç‡®∞‡®æ‡®Ç‡®ú‡®º‡©à‡®ï‡®∏‡®º‡®® ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®®**: ACID ‡®Ö‡®®‡©Å‡®ï‡©Ç‡®≤‡®§‡®æ ‡®Ö‡®§‡©á ‡®∞‡©ã‡®≤‡®¨‡©à‡®ï ‡®π‡©à‡®Ç‡®°‡®≤‡®ø‡©∞‡®ó  
- **‡®™‡©Å‡©±‡®õ‡®ó‡®ø‡©±‡®õ ‡®Ö‡®ß‡®ø‡®ï‡®§‡®Æ**: ‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®® ‡®Æ‡®æ‡®®‡©Ä‡®ü‡®∞‡®ø‡©∞‡®ó ‡®Ö‡®§‡©á ‡®Ö‡®ß‡®ø‡®ï‡®§‡®Æ  
- **RLS ‡®á‡©∞‡®ü‡©Ä‡®ó‡©ç‡®∞‡©á‡®∏‡®º‡®®**: ‡®∞‡©ã‡®Ö-‡®≤‡©à‡®µ‡®≤ ‡®∏‡©Å‡®∞‡©±‡®ñ‡®ø‡®Ü ‡®∏‡©∞‡®¶‡®∞‡®≠ ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®®  

### ‡®≤‡©á‡®Ö‡®∞ 4: ‡®á‡©∞‡®´‡®∞‡®æ‡®∏‡®ü‡®∞‡®ï‡®ö‡®∞ ‡®≤‡©á‡®Ö‡®∞
**‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞‡©Ä**: ‡®≤‡©å‡®ó‡®ø‡©∞‡®ó, ‡®Æ‡®æ‡®®‡©Ä‡®ü‡®∞‡®ø‡©∞‡®ó, ‡®Ö‡®§‡©á ‡®ï‡®®‡®´‡®ø‡®ó‡®∞‡©á‡®∏‡®º‡®® ‡®µ‡®∞‡®ó‡©á ‡®ï‡©ç‡®∞‡®æ‡®∏-‡®ï‡®ü‡®ø‡©∞‡®ó ‡®ö‡®ø‡©∞‡®§‡®æ‡®µ‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®≠‡®æ‡®≤‡®£‡®æ

```python
class InfrastructureManager:
    """Infrastructure concerns management."""
    
    def __init__(self):
        self.logger = self._setup_logging()
        self.metrics = self._setup_metrics()
        self.config = self._load_configuration()
    
    def _setup_logging(self) -> Logger:
        """Configure structured logging."""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('mcp_server.log')
            ]
        )
        return logging.getLogger(__name__)
    
    async def track_query_execution(
        self, 
        query_type: str, 
        duration: float, 
        success: bool
    ):
        """Track query performance metrics."""
        self.metrics.counter('query_total').labels(
            type=query_type,
            status='success' if success else 'error'
        ).inc()
        
        self.metrics.histogram('query_duration').labels(
            type=query_type
        ).observe(duration)
```

## üóÑÔ∏è ‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®°‡®ø‡®ú‡®º‡®æ‡®à‡®® ‡®™‡©à‡®ü‡®∞‡®®

‡®∏‡®æ‡®°‡®æ PostgreSQL ‡®∏‡®ï‡©Ä‡®Æ‡®æ ‡®Æ‡®≤‡®ü‡©Ä-‡®ü‡©à‡®®‡©à‡®Ç‡®ü MCP ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®≤‡®à ‡®ï‡®à ‡®Æ‡©Å‡©±‡®ñ ‡®™‡©à‡®ü‡®∞‡®®‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Ö‡®Æ‡®≤ ‡®µ‡®ø‡©±‡®ö ‡®≤‡®ø‡®Ü‡®â‡®Ç‡®¶‡®æ ‡®π‡©à:

### 1. ‡®Æ‡®≤‡®ü‡©Ä-‡®ü‡©à‡®®‡©à‡®Ç‡®ü ‡®∏‡®ï‡©Ä‡®Æ‡®æ ‡®°‡®ø‡®ú‡®º‡®æ‡®à‡®®

```sql
-- Core retail entities with store-based partitioning
CREATE TABLE retail.stores (
    store_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    location VARCHAR(200) NOT NULL,
    manager_id UUID NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.customers (
    customer_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    store_id UUID REFERENCES retail.stores(store_id),
    first_name VARCHAR(50) NOT NULL,
    last_name VARCHAR(50) NOT NULL,
    email VARCHAR(100) UNIQUE,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.orders (
    order_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    customer_id UUID REFERENCES retail.customers(customer_id),
    store_id UUID REFERENCES retail.stores(store_id),
    order_date TIMESTAMP DEFAULT NOW(),
    total_amount DECIMAL(10,2) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending'
);
```

**‡®°‡®ø‡®ú‡®º‡®æ‡®à‡®® ‡®∏‡®ø‡®ß‡®æ‡®Ç‡®§**:
- **‡®´‡©ã‡®∞‡®® ‡®ï‡©Ä ‡®∏‡®•‡®ø‡®∞‡®§‡®æ**: ‡®ü‡©á‡®¨‡®≤‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®°‡®æ‡®ü‡®æ ‡®¶‡©Ä ‡®∏‡©±‡®ö‡®æ‡®à ‡®®‡©Ç‡©∞ ‡®Ø‡®ï‡©Ä‡®®‡©Ä ‡®¨‡®£‡®æ‡®â‡®£‡®æ  
- **‡®∏‡®ü‡©ã‡®∞ ID ‡®™‡©ç‡®∞‡®∏‡®æ‡®∞‡®®**: ‡®π‡®∞ ‡®≤‡©à‡®£-‡®¶‡©á‡®£ ‡®µ‡®æ‡®≤‡©Ä ‡®ü‡©á‡®¨‡®≤ ‡®µ‡®ø‡©±‡®ö store_id ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®π‡©à  
- **UUID ‡®™‡©ç‡®∞‡®æ‡®á‡®Æ‡®∞‡©Ä ‡®ï‡©Ä‡®ú‡®º**: ‡®µ‡©∞‡®°‡©á ‡®∏‡®ø‡®∏‡®ü‡®Æ‡®æ‡®Ç ‡®≤‡®à ‡®µ‡®ø‡®∏‡®º‡®µ-‡®µ‡®ø‡®Ü‡®™‡©Ä ‡®µ‡®ø‡®≤‡©±‡®ñ‡®£ ‡®™‡®õ‡®æ‡®£‡®ï‡®∞‡®§‡®æ  
- **‡®ü‡®æ‡®à‡®Æ‡®∏‡®ü‡©à‡®Ç‡®™ ‡®ü‡©ç‡®∞‡©à‡®ï‡®ø‡©∞‡®ó**: ‡®∏‡®æ‡®∞‡©á ‡®°‡®æ‡®ü‡®æ ‡®¨‡®¶‡®≤‡®æ‡®Ö ‡®≤‡®à ‡®Ü‡®°‡®ø‡®ü ‡®ü‡©ç‡®∞‡©á‡®≤  

### 2. ‡®∞‡©ã‡®Ö ‡®≤‡©à‡®µ‡®≤ ‡®∏‡©Å‡®∞‡©±‡®ñ‡®ø‡®Ü ‡®Ö‡®Æ‡®≤

```sql
-- Enable RLS on multi-tenant tables
ALTER TABLE retail.customers ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.orders ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.order_items ENABLE ROW LEVEL SECURITY;

-- Store manager can only see their store's data
CREATE POLICY store_manager_customers ON retail.customers
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

CREATE POLICY store_manager_orders ON retail.orders
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

-- Regional managers see multiple stores
CREATE POLICY regional_manager_orders ON retail.orders
    FOR ALL TO regional_managers
    USING (store_id = ANY(get_user_store_list()));

-- Support function for RLS context
CREATE OR REPLACE FUNCTION get_current_user_store()
RETURNS UUID AS $$
BEGIN
    RETURN current_setting('app.current_rls_user_id')::UUID;
EXCEPTION WHEN OTHERS THEN
    RETURN '00000000-0000-0000-0000-000000000000'::UUID;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

**RLS ‡®´‡®æ‡®á‡®¶‡©á**:
- **‡®Ü‡®ü‡©ã‡®Æ‡©à‡®ü‡®ø‡®ï ‡®´‡®ø‡®≤‡®ü‡®∞‡®ø‡©∞‡®ó**: ‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®°‡®æ‡®ü‡®æ ‡®Ü‡®à‡®∏‡©ã‡®≤‡©á‡®∏‡®º‡®® ‡®®‡©Ç‡©∞ ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à  
- **‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®∏‡®æ‡®¶‡®ó‡©Ä**: ‡®ï‡©ã‡®à ‡®ú‡®ü‡®ø‡®≤ WHERE ‡®ï‡®≤‡©å‡®ú‡®º ‡®¶‡©Ä ‡®≤‡©ã‡©ú ‡®®‡®π‡©Ä‡®Ç  
- **‡®∏‡©Å‡®∞‡©±‡®ñ‡®ø‡®Ü ‡®°‡®ø‡®´‡®æ‡®≤‡®ü ‡®¶‡©Å‡®Ü‡®∞‡®æ**: ‡®ó‡®≤‡®§‡©Ä ‡®®‡®æ‡®≤ ‡®ó‡®≤‡®§ ‡®°‡®æ‡®ü‡®æ ‡®§‡©±‡®ï ‡®™‡®π‡©Å‡©∞‡®ö‡®£‡®æ ‡®Ö‡®∏‡©∞‡®≠‡®µ  
- **‡®Ü‡®°‡®ø‡®ü ‡®Ö‡®®‡©Å‡®ï‡©Ç‡®≤‡®§‡®æ**: ‡®∏‡®™‡®∏‡®º‡®ü ‡®°‡®æ‡®ü‡®æ ‡®™‡®π‡©Å‡©∞‡®ö ‡®∏‡©Ä‡®Æ‡®æ‡®µ‡®æ‡®Ç  

### 3. ‡®µ‡©à‡®ï‡®ü‡®∞ ‡®ñ‡©ã‡®ú ‡®∏‡®ï‡©Ä‡®Æ‡®æ

```sql
-- Product embeddings for semantic search
CREATE TABLE retail.product_description_embeddings (
    product_id UUID PRIMARY KEY REFERENCES retail.products(product_id),
    description_embedding vector(1536),
    last_updated TIMESTAMP DEFAULT NOW()
);

-- Optimize vector similarity search
CREATE INDEX idx_product_embeddings_vector 
ON retail.product_description_embeddings 
USING ivfflat (description_embedding vector_cosine_ops);

-- Semantic search function
CREATE OR REPLACE FUNCTION search_products_by_description(
    query_embedding vector(1536),
    similarity_threshold FLOAT DEFAULT 0.7,
    max_results INTEGER DEFAULT 20
)
RETURNS TABLE(
    product_id UUID,
    name VARCHAR,
    description TEXT,
    similarity_score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        p.product_id,
        p.name,
        p.description,
        (1 - (pde.description_embedding <=> query_embedding)) AS similarity_score
    FROM retail.products p
    JOIN retail.product_description_embeddings pde ON p.product_id = pde.product_id
    WHERE (pde.description_embedding <=> query_embedding) <= (1 - similarity_threshold)
    ORDER BY similarity_score DESC
    LIMIT max_results;
END;
$$ LANGUAGE plpgsql;
```

## üîå ‡®ï‡®®‡©à‡®ï‡®∏‡®º‡®® ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®® ‡®™‡©à‡®ü‡®∞‡®®

‡®ï‡©Å‡®∏‡®º‡®≤ ‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®ï‡®®‡©à‡®ï‡®∏‡®º‡®® ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®® MCP ‡®∏‡®∞‡®µ‡®∞ ‡®¶‡©á ‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®® ‡®≤‡®à ‡®Æ‡®π‡©±‡®§‡®µ‡®™‡©Ç‡®∞‡®® ‡®π‡©à:

### ‡®ï‡®®‡©à‡®ï‡®∏‡®º‡®® ‡®™‡©Ç‡®≤ ‡®ï‡®®‡®´‡®ø‡®ó‡®∞‡©á‡®∏‡®º‡®®

```python
class ConnectionPoolManager:
    """Manages PostgreSQL connection pools."""
    
    async def create_pool(self) -> Pool:
        """Create optimized connection pool."""
        return await asyncpg.create_pool(
            host=self.config.db_host,
            port=self.config.db_port,
            database=self.config.db_name,
            user=self.config.db_user,
            password=self.config.db_password,
            
            # Pool configuration
            min_size=2,          # Minimum connections
            max_size=10,         # Maximum connections
            max_inactive_connection_lifetime=300,  # 5 minutes
            
            # Query configuration
            command_timeout=30,   # Query timeout
            server_settings={
                "application_name": "zava-mcp-server",
                "jit": "off",          # Disable JIT for stability
                "work_mem": "4MB",     # Limit work memory
                "statement_timeout": "30s"
            }
        )
    
    async def execute_with_retry(
        self, 
        query: str, 
        params: Tuple = None,
        max_retries: int = 3
    ) -> List[Dict[str, Any]]:
        """Execute query with automatic retry logic."""
        
        for attempt in range(max_retries):
            try:
                async with self.pool.acquire() as conn:
                    if params:
                        rows = await conn.fetch(query, *params)
                    else:
                        rows = await conn.fetch(query)
                    return [dict(row) for row in rows]
                    
            except (ConnectionError, InterfaceError) as e:
                if attempt == max_retries - 1:
                    raise
                
                # Exponential backoff
                await asyncio.sleep(2 ** attempt)
                logger.warning(f"Database connection failed, retrying ({attempt + 1}/{max_retries})")
```

### ‡®∏‡®∞‡©ã‡®§ ‡®ú‡©Ä‡®µ‡®®‡®ö‡©±‡®ï‡®∞ ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®®

```python
class MCPServerManager:
    """Manages MCP server lifecycle and resources."""
    
    async def startup(self):
        """Initialize server resources."""
        # Create database connection pool
        self.db_pool = await self.pool_manager.create_pool()
        
        # Initialize AI services
        self.ai_client = await self.create_ai_client()
        
        # Setup monitoring
        self.metrics_collector = MetricsCollector()
        
        logger.info("MCP server startup complete")
    
    async def shutdown(self):
        """Cleanup server resources."""
        try:
            # Close database connections
            if self.db_pool:
                await self.db_pool.close()
            
            # Cleanup AI client
            if self.ai_client:
                await self.ai_client.close()
            
            # Flush metrics
            await self.metrics_collector.flush()
            
            logger.info("MCP server shutdown complete")
            
        except Exception as e:
            logger.error(f"Error during shutdown: {e}")
    
    async def health_check(self) -> Dict[str, str]:
        """Verify server health status."""
        status = {}
        
        # Check database connection
        try:
            async with self.db_pool.acquire() as conn:
                await conn.fetchval("SELECT 1")
            status["database"] = "healthy"
        except Exception as e:
            status["database"] = f"unhealthy: {e}"
        
        # Check AI service
        try:
            await self.ai_client.health_check()
            status["ai_service"] = "healthy"
        except Exception as e:
            status["ai_service"] = f"unhealthy: {e}"
        
        return status
```

## üõ°Ô∏è ‡®ê‡®∞‡®∞ ‡®π‡©à‡®Ç‡®°‡®≤‡®ø‡©∞‡®ó ‡®Ö‡®§‡©á ‡®≤‡®ö‡®ï‡®¶‡®æ‡®∞‡®§‡®æ ‡®™‡©à‡®ü‡®∞‡®®

‡®Æ‡®ú‡®º‡®¨‡©Ç‡®§ ‡®ê‡®∞‡®∞ ‡®π‡©à‡®Ç‡®°‡®≤‡®ø‡©∞‡®ó ‡®Ø‡®ï‡©Ä‡®®‡©Ä ‡®¨‡®£‡®æ‡®â‡®Ç‡®¶‡©Ä ‡®π‡©à ‡®ï‡®ø MCP ‡®∏‡®∞‡®µ‡®∞ ‡®≠‡®∞‡©ã‡®∏‡©á‡®Ø‡©ã‡®ó ‡®§‡®∞‡©Ä‡®ï‡©á ‡®®‡®æ‡®≤ ‡®ï‡©∞‡®Æ ‡®ï‡®∞‡©á:

### ‡®π‡®æ‡®á‡®∞‡®æ‡®∞‡®ï‡©Ä‡®ï‡®≤ ‡®ê‡®∞‡®∞ ‡®ï‡®ø‡®∏‡®Æ‡®æ‡®Ç

```python
class MCPError(Exception):
    """Base MCP server error."""
    def __init__(self, message: str, error_code: str = "MCP_ERROR"):
        self.message = message
        self.error_code = error_code
        super().__init__(message)

class DatabaseError(MCPError):
    """Database operation errors."""
    def __init__(self, message: str, query: str = None):
        super().__init__(message, "DATABASE_ERROR")
        self.query = query

class AuthorizationError(MCPError):
    """Access control errors."""
    def __init__(self, message: str, user_id: str = None):
        super().__init__(message, "AUTHORIZATION_ERROR")
        self.user_id = user_id

class QueryTimeoutError(DatabaseError):
    """Query execution timeout."""
    def __init__(self, query: str):
        super().__init__(f"Query timeout: {query[:100]}...", query)
        self.error_code = "QUERY_TIMEOUT"

class ValidationError(MCPError):
    """Input validation errors."""
    def __init__(self, field: str, value: Any, constraint: str):
        message = f"Validation failed for {field}: {constraint}"
        super().__init__(message, "VALIDATION_ERROR")
        self.field = field
        self.value = value
```

### ‡®ê‡®∞‡®∞ ‡®π‡©à‡®Ç‡®°‡®≤‡®ø‡©∞‡®ó ‡®Æ‡®ø‡®°‡®≤‡®µ‡©á‡®Ö‡®∞

```python
@contextmanager
async def error_handling_context(operation_name: str, user_id: str = None):
    """Centralized error handling for operations."""
    start_time = time.time()
    
    try:
        yield
        
        # Success metrics
        duration = time.time() - start_time
        metrics.operation_success.labels(operation=operation_name).inc()
        metrics.operation_duration.labels(operation=operation_name).observe(duration)
        
    except ValidationError as e:
        logger.warning(f"Validation error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "validation",
            "field": e.field
        })
        metrics.operation_error.labels(operation=operation_name, type="validation").inc()
        raise
        
    except AuthorizationError as e:
        logger.warning(f"Authorization error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "authorization"
        })
        metrics.operation_error.labels(operation=operation_name, type="authorization").inc()
        raise
        
    except DatabaseError as e:
        logger.error(f"Database error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "database",
            "query": e.query[:100] if e.query else None
        })
        metrics.operation_error.labels(operation=operation_name, type="database").inc()
        raise
        
    except Exception as e:
        logger.error(f"Unexpected error in {operation_name}: {str(e)}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "unexpected"
        }, exc_info=True)
        metrics.operation_error.labels(operation=operation_name, type="unexpected").inc()
        raise MCPError(f"Internal server error in {operation_name}")
```

## üìä ‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®® ‡®Ö‡®ß‡®ø‡®ï‡®§‡®Æ ‡®∞‡®£‡®®‡©Ä‡®§‡©Ä‡®Ü‡®Ç

### ‡®™‡©Å‡©±‡®õ‡®ó‡®ø‡©±‡®õ ‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®® ‡®Æ‡®æ‡®®‡©Ä‡®ü‡®∞‡®ø‡©∞‡®ó

```python
class QueryPerformanceMonitor:
    """Monitor and optimize query performance."""
    
    def __init__(self):
        self.slow_query_threshold = 1.0  # seconds
        self.query_stats = defaultdict(list)
    
    @contextmanager
    async def monitor_query(self, query: str, operation_type: str = "unknown"):
        """Monitor query execution time and performance."""
        start_time = time.time()
        query_hash = hashlib.md5(query.encode()).hexdigest()[:8]
        
        try:
            yield
            
            duration = time.time() - start_time
            
            # Record performance metrics
            self.query_stats[operation_type].append(duration)
            
            # Log slow queries
            if duration > self.slow_query_threshold:
                logger.warning(f"Slow query detected", extra={
                    "query_hash": query_hash,
                    "duration": duration,
                    "operation_type": operation_type,
                    "query": query[:200]
                })
            
            # Update metrics
            metrics.query_duration.labels(type=operation_type).observe(duration)
            
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Query failed", extra={
                "query_hash": query_hash,
                "duration": duration,
                "operation_type": operation_type,
                "error": str(e)
            })
            raise
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Generate performance summary report."""
        summary = {}
        
        for operation_type, durations in self.query_stats.items():
            if durations:
                summary[operation_type] = {
                    "count": len(durations),
                    "avg_duration": sum(durations) / len(durations),
                    "max_duration": max(durations),
                    "min_duration": min(durations),
                    "slow_queries": len([d for d in durations if d > self.slow_query_threshold])
                }
        
        return summary
```

### ‡®ï‡©à‡®∏‡®º‡®ø‡©∞‡®ó ‡®∞‡®£‡®®‡©Ä‡®§‡©Ä

```python
class QueryCache:
    """Intelligent query result caching."""
    
    def __init__(self, redis_url: str = None):
        self.cache = {}  # In-memory fallback
        self.redis_client = redis.Redis.from_url(redis_url) if redis_url else None
        self.cache_ttl = 300  # 5 minutes default
    
    async def get_cached_result(
        self, 
        cache_key: str, 
        query_func: Callable,
        ttl: int = None
    ) -> Any:
        """Get result from cache or execute query."""
        ttl = ttl or self.cache_ttl
        
        # Try cache first
        cached_result = await self._get_from_cache(cache_key)
        if cached_result is not None:
            metrics.cache_hit.labels(type="query").inc()
            return cached_result
        
        # Execute query
        metrics.cache_miss.labels(type="query").inc()
        result = await query_func()
        
        # Cache result
        await self._set_in_cache(cache_key, result, ttl)
        
        return result
    
    def _generate_cache_key(self, query: str, user_context: str) -> str:
        """Generate consistent cache key."""
        key_data = f"{query}:{user_context}"
        return hashlib.sha256(key_data.encode()).hexdigest()
```

## üéØ ‡®Æ‡©Å‡©±‡®ñ ‡®®‡®ø‡®∏‡®º‡®ö‡©á

‡®á‡®∏ ‡®Æ‡©ã‡®°‡®ø‡®ä‡®≤ ‡®®‡©Ç‡©∞ ‡®™‡©Ç‡®∞‡®æ ‡®ï‡®∞‡®® ‡®¶‡©á ‡®¨‡®æ‡®Ö‡®¶, ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®∏‡®Æ‡®ù ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã:

‚úÖ **‡®≤‡©á‡®Ö‡®∞‡®° ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞**: MCP ‡®∏‡®∞‡®µ‡®∞ ‡®°‡®ø‡®ú‡®º‡®æ‡®à‡®® ‡®µ‡®ø‡©±‡®ö ‡®ö‡®ø‡©∞‡®§‡®æ‡®µ‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®µ‡©±‡®ñ ‡®ï‡®∞‡®®‡®æ  
‚úÖ **‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®™‡©à‡®ü‡®∞‡®®**: ‡®Æ‡®≤‡®ü‡©Ä-‡®ü‡©à‡®®‡©à‡®Ç‡®ü ‡®∏‡®ï‡©Ä‡®Æ‡®æ ‡®°‡®ø‡®ú‡®º‡®æ‡®à‡®® ‡®Ö‡®§‡©á RLS ‡®Ö‡®Æ‡®≤  
‚úÖ **‡®ï‡®®‡©à‡®ï‡®∏‡®º‡®® ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®®**: ‡®ï‡©Å‡®∏‡®º‡®≤ ‡®™‡©Ç‡®≤‡®ø‡©∞‡®ó ‡®Ö‡®§‡©á ‡®∏‡®∞‡©ã‡®§ ‡®ú‡©Ä‡®µ‡®®‡®ö‡©±‡®ï‡®∞  
‚úÖ **‡®ê‡®∞‡®∞ ‡®π‡©à‡®Ç‡®°‡®≤‡®ø‡©∞‡®ó**: ‡®π‡®æ‡®á‡®∞‡®æ‡®∞‡®ï‡©Ä‡®ï‡®≤ ‡®ê‡®∞‡®∞ ‡®ï‡®ø‡®∏‡®Æ‡®æ‡®Ç ‡®Ö‡®§‡©á ‡®≤‡®ö‡®ï‡®¶‡®æ‡®∞‡®§‡®æ ‡®™‡©à‡®ü‡®∞‡®®  
‚úÖ **‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®® ‡®Ö‡®ß‡®ø‡®ï‡®§‡®Æ**: ‡®Æ‡®æ‡®®‡©Ä‡®ü‡®∞‡®ø‡©∞‡®ó, ‡®ï‡©à‡®∏‡®º‡®ø‡©∞‡®ó, ‡®Ö‡®§‡©á ‡®™‡©Å‡©±‡®õ‡®ó‡®ø‡©±‡®õ ‡®Ö‡®ß‡®ø‡®ï‡®§‡®Æ  
‚úÖ **‡®™‡©ç‡®∞‡©ã‡®°‡®ï‡®∏‡®º‡®® ‡®§‡®ø‡®Ü‡®∞‡©Ä**: ‡®á‡©∞‡®´‡®∞‡®æ‡®∏‡®ü‡®∞‡®ï‡®ö‡®∞ ‡®ö‡®ø‡©∞‡®§‡®æ‡®µ‡®æ‡®Ç ‡®Ö‡®§‡©á ‡®ì‡®™‡®∞‡©á‡®∏‡®º‡®®‡®≤ ‡®™‡©à‡®ü‡®∞‡®®  

## üöÄ ‡®Ö‡®ó‡®≤‡®æ ‡®ï‡©Ä ‡®π‡©à

**[Module 02: Security and Multi-Tenancy](../02-Security/README.md)** ‡®®‡®æ‡®≤ ‡®ú‡®æ‡®∞‡©Ä ‡®∞‡©±‡®ñ‡©ã:

- ‡®∞‡©ã‡®Ö ‡®≤‡©à‡®µ‡®≤ ‡®∏‡©Å‡®∞‡©±‡®ñ‡®ø‡®Ü ‡®Ö‡®Æ‡®≤ ‡®¶‡©á ‡®µ‡©á‡®∞‡®µ‡©á  
- ‡®™‡©ç‡®∞‡®Æ‡®æ‡®£‡®ø‡®ï‡®§‡®æ ‡®Ö‡®§‡©á ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞ ‡®™‡©à‡®ü‡®∞‡®®  
- ‡®Æ‡®≤‡®ü‡©Ä-‡®ü‡©à‡®®‡©à‡®Ç‡®ü ‡®°‡®æ‡®ü‡®æ ‡®Ü‡®à‡®∏‡©ã‡®≤‡©á‡®∏‡®º‡®® ‡®∞‡®£‡®®‡©Ä‡®§‡©Ä‡®Ü‡®Ç  
- ‡®∏‡©Å‡®∞‡©±‡®ñ‡®ø‡®Ü ‡®Ü‡®°‡®ø‡®ü ‡®Ö‡®§‡©á ‡®Ö‡®®‡©Å‡®ï‡©Ç‡®≤‡®§‡®æ ‡®µ‡®ø‡®ö‡®æ‡®∞  

## üìö ‡®µ‡®æ‡®ß‡©Ç ‡®∏‡®∞‡©ã‡®§

### ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞ ‡®™‡©à‡®ü‡®∞‡®®
- [Clean Architecture in Python](https://github.com/cosmic-python/code) - ‡®™‡®æ‡®á‡®•‡®® ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®®‡®æ‡®Ç ‡®≤‡®à ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞ ‡®™‡©à‡®ü‡®∞‡®®  
- [Database Design Patterns](https://en.wikipedia.org/wiki/Database_design) - ‡®∞‡®ø‡®≤‡©á‡®∏‡®º‡®®‡®≤ ‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®°‡®ø‡®ú‡®º‡®æ‡®à‡®® ‡®∏‡®ø‡®ß‡®æ‡®Ç‡®§  
- [Microservices Patterns](https://microservices.io/patterns/) - ‡®∏‡©á‡®µ‡®æ ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞ ‡®™‡©à‡®ü‡®∞‡®®  

### PostgreSQL ‡®â‡©±‡®®‡®§ ‡®µ‡®ø‡®∏‡®º‡©á
- [PostgreSQL Performance Tuning](https://wiki.postgresql.org/wiki/Performance_Optimization) - ‡®°‡®æ‡®ü‡®æ‡®¨‡©á‡®∏ ‡®Ö‡®ß‡®ø‡®ï‡®§‡®Æ ‡®ó‡®æ‡®à‡®°  
- [Connection Pooling Best Practices](https://www.postgresql.org/docs/current/runtime-config-connection.html) - ‡®ï‡®®‡©à‡®ï‡®∏‡®º‡®® ‡®™‡©ç‡®∞‡®¨‡©∞‡®ß‡®®  
- [Query Planning and Optimization](https://www.postgresql.org/docs/current/planner-optimizer.html) - ‡®™‡©Å‡©±‡®õ‡®ó‡®ø‡©±‡®õ ‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®®  

### Python Async Patterns
- [AsyncIO Best Practices](https://docs.python.org/3/library/asyncio.html) - ‡®ê‡®∏‡®ø‡©∞‡®ï ‡®™‡©ç‡®∞‡©ã‡®ó‡®∞‡®æ‡®Æ‡®ø‡©∞‡®ó ‡®™‡©à‡®ü‡®∞‡®®  
- [FastAPI Architecture](https://fastapi.tiangolo.com/advanced/) - ‡®Ü‡®ß‡©Å‡®®‡®ø‡®ï ‡®™‡®æ‡®á‡®•‡®® ‡®µ‡©à‡©±‡®¨ ‡®Ü‡®∞‡®ï‡©Ä‡®ü‡©à‡®ï‡®ö‡®∞  
- [Pydantic Models](https://pydantic-docs.helpmanual.io/) - ‡®°‡®æ‡®ü‡®æ ‡®µ‡©à‡®∞‡©Ä‡®´‡®ø‡®ï‡©á‡®∏‡®º‡®® ‡®Ö‡®§‡©á ‡®∏‡©Ä‡®∞‡©Ä‡®Ö‡®≤‡®æ‡®à‡®ú‡®º‡©á‡®∏‡®º‡®®  

---

**‡®Ö‡®ó‡®≤‡®æ**: ‡®∏‡©Å‡®∞‡©±‡®ñ‡®ø‡®Ü ‡®™‡©à‡®ü‡®∞‡®®‡®æ‡®Ç ‡®¶‡©Ä ‡®ñ‡©ã‡®ú ‡®ï‡®∞‡®® ‡®≤‡®à ‡®§‡®ø‡®Ü‡®∞? [Module 02: Security and Multi-Tenancy](../02-Security/README.md) ‡®®‡®æ‡®≤ ‡®ú‡®æ‡®∞‡©Ä ‡®∞‡©±‡®ñ‡©ã

---

**‡®Ö‡®∏‡®µ‡©Ä‡®ï‡®∞‡®§‡®æ**:  
‡®á‡®π ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º AI ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®∏‡©á‡®µ‡®æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§ ‡®ú‡®¶‡©ã‡®Ç ‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®π‡©Ä ‡®π‡©ã‡®£ ‡®¶‡®æ ‡®Ø‡®§‡®® ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®ß‡®ø‡®Ü‡®® ‡®¶‡®ø‡®ì ‡®ï‡®ø ‡®∏‡®µ‡©à‡®ö‡®æ‡®≤‡®ø‡®§ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®ó‡®≤‡®§‡©Ä‡®Ü‡®Ç ‡®ú‡®æ‡®Ç ‡®Ö‡®∏‡©Å‡©±‡®§‡©Ä‡®Ü‡®Ç ‡®π‡©ã ‡®∏‡®ï‡®¶‡©Ä‡®Ü‡®Ç ‡®π‡®®‡•§ ‡®á‡®∏ ‡®¶‡©Ä ‡®Æ‡©Ç‡®≤ ‡®≠‡®æ‡®∏‡®º‡®æ ‡®µ‡®ø‡©±‡®ö ‡®Æ‡©Ç‡®≤ ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º ‡®®‡©Ç‡©∞ ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞‡®§ ‡®∏‡®∞‡©ã‡®§ ‡®Æ‡©∞‡®®‡®ø‡®Ü ‡®ú‡®æ‡®£‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à‡•§ ‡®Æ‡®π‡©±‡®§‡®µ‡®™‡©Ç‡®∞‡®® ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®≤‡®à, ‡®™‡©á‡®∏‡®º‡©á‡®µ‡®∞ ‡®Æ‡®®‡©Å‡©±‡®ñ‡©Ä ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®∏‡®ø‡®´‡®æ‡®∞‡®∏‡®º ‡®ï‡©Ä‡®§‡©Ä ‡®ú‡®æ‡®Ç‡®¶‡©Ä ‡®π‡©à‡•§ ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡®∏ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®§‡©ã‡®Ç ‡®™‡©à‡®¶‡®æ ‡®π‡©ã‡®£ ‡®µ‡®æ‡®≤‡©á ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®ó‡®≤‡®§ ‡®´‡®π‡®ø‡®Æ‡©Ä ‡®ú‡®æ‡®Ç ‡®ó‡®≤‡®§ ‡®µ‡®ø‡®Ü‡®ñ‡®ø‡®Ü ‡®≤‡®à ‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞ ‡®®‡®π‡©Ä‡®Ç ‡®π‡®æ‡®Ç‡•§