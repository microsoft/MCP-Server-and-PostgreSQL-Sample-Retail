<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "907b008a90c728fd33a1c0f66889e8e2",
  "translation_date": "2025-09-29T19:53:39+00:00",
  "source_file": "walkthrough/01-Architecture/README.md",
  "language_code": "mr"
}
-->
# ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§∏‡§Ç‡§ï‡§≤‡•ç‡§™‡§®‡§æ

## üéØ ‡§Ø‡§æ ‡§Æ‡•â‡§°‡•ç‡§Ø‡•Ç‡§≤‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ï‡§æ‡§Ø ‡§∏‡§Æ‡§æ‡§µ‡§ø‡§∑‡•ç‡§ü ‡§Ü‡§π‡•á

‡§π‡§æ ‡§Æ‡•â‡§°‡•ç‡§Ø‡•Ç‡§≤ MCP ‡§∏‡§∞‡•ç‡§µ‡•ç‡§π‡§∞ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏, ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§°‡§ø‡§ù‡§æ‡§á‡§® ‡§§‡§§‡•ç‡§§‡•ç‡§µ‡•á ‡§Ü‡§£‡§ø ‡§Æ‡§ú‡§¨‡•Ç‡§§, ‡§∏‡•ç‡§ï‡•á‡§≤‡•á‡§¨‡§≤ ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏-‡§á‡§Ç‡§ü‡§ø‡§ó‡•ç‡§∞‡•á‡§ü‡•á‡§° AI ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§æ‡§Ç‡§®‡§æ ‡§ö‡§æ‡§≤‡§®‡§æ ‡§¶‡•á‡§£‡§æ‡§±‡•ç‡§Ø‡§æ ‡§§‡§æ‡§Ç‡§§‡•ç‡§∞‡§ø‡§ï ‡§Ö‡§Ç‡§Æ‡§≤‡§¨‡§ú‡§æ‡§µ‡§£‡•Ä ‡§ß‡•ã‡§∞‡§£‡§æ‡§Ç‡§ö‡§æ ‡§∏‡§ñ‡•ã‡§≤ ‡§Ö‡§≠‡•ç‡§Ø‡§æ‡§∏ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡•ã.

## ‡§Ü‡§¢‡§æ‡§µ‡§æ

‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§á‡§Ç‡§ü‡§ø‡§ó‡•ç‡§∞‡•á‡§∂‡§®‡§∏‡§π ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§®-‡§§‡§Ø‡§æ‡§∞ MCP ‡§∏‡§∞‡•ç‡§µ‡•ç‡§π‡§∞ ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§£‡•á ‡§ï‡§æ‡§≥‡§ú‡•Ä‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞‡§≤ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø‡§æ‡§Ç‡§ö‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§Ö‡§∏‡§§‡•á. ‡§π‡§æ ‡§Æ‡•â‡§°‡•ç‡§Ø‡•Ç‡§≤ ‡§Ü‡§Æ‡§ö‡•ç‡§Ø‡§æ Zava Retail ‡§Ö‡•Ö‡§®‡§æ‡§≤‡§ø‡§ü‡§ø‡§ï‡•ç‡§∏ ‡§∏‡•ã‡§≤‡•ç‡§Ø‡•Ç‡§∂‡§®‡§≤‡§æ ‡§Æ‡§ú‡§¨‡•Ç‡§§, ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§Ü‡§£‡§ø ‡§∏‡•ç‡§ï‡•á‡§≤‡•á‡§¨‡§≤ ‡§¨‡§®‡§µ‡§£‡§æ‡§±‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ò‡§ü‡§ï, ‡§°‡§ø‡§ù‡§æ‡§á‡§® ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏ ‡§Ü‡§£‡§ø ‡§§‡§æ‡§Ç‡§§‡•ç‡§∞‡§ø‡§ï ‡§µ‡§ø‡§ö‡§æ‡§∞‡§æ‡§Ç‡§ö‡•á ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞‡§§‡•ã.

‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§∏‡•ç‡§§‡§∞ ‡§ï‡§∏‡§æ ‡§∏‡§Ç‡§µ‡§æ‡§¶ ‡§∏‡§æ‡§ß‡§§‡•ã, ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§§‡§Ç‡§§‡•ç‡§∞‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡§æ ‡§®‡§ø‡§µ‡§°‡§≤‡•á ‡§ó‡•á‡§≤‡•á ‡§Ü‡§£‡§ø MCP ‡§Ö‡§Ç‡§Æ‡§≤‡§¨‡§ú‡§æ‡§µ‡§£‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§π‡•á ‡§™‡•Ö‡§ü‡§∞‡•ç‡§® ‡§ï‡§∏‡•á ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§æ‡§Ø‡§ö‡•á ‡§π‡•á ‡§∏‡§Æ‡§ú‡•á‡§≤.

## ‡§∂‡§ø‡§ï‡§£‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§â‡§¶‡•ç‡§¶‡§ø‡§∑‡•ç‡§ü‡•á

‡§Ø‡§æ ‡§Æ‡•â‡§°‡•ç‡§Ø‡•Ç‡§≤‡§ö‡•ç‡§Ø‡§æ ‡§∂‡•á‡§µ‡§ü‡•Ä, ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§Ö‡§∏‡§æ‡§≤:

- **‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£**: ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§á‡§Ç‡§ü‡§ø‡§ó‡•ç‡§∞‡•á‡§∂‡§®‡§∏‡§π MCP ‡§∏‡§∞‡•ç‡§µ‡•ç‡§π‡§∞‡§ö‡•Ä ‡§∏‡•ç‡§§‡§∞‡§ø‡§§ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞
- **‡§∏‡§Æ‡§ú‡•Ç‡§® ‡§ò‡•á‡§£‡•á**: ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞‡§≤ ‡§ò‡§ü‡§ï‡§æ‡§ö‡•Ä ‡§≠‡•Ç‡§Æ‡§ø‡§ï‡§æ ‡§Ü‡§£‡§ø ‡§ú‡§¨‡§æ‡§¨‡§¶‡§æ‡§±‡•ç‡§Ø‡§æ
- **‡§°‡§ø‡§ù‡§æ‡§á‡§®**: ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§ü‡•á‡§®‡§Ç‡§ü MCP ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§æ‡§Ç‡§®‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§¶‡•á‡§£‡§æ‡§±‡•ç‡§Ø‡§æ ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§∏‡•ç‡§ï‡•Ä‡§Æ
- **‡§Ö‡§Ç‡§Æ‡§≤‡§¨‡§ú‡§æ‡§µ‡§£‡•Ä**: ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§™‡•Ç‡§≤‡§ø‡§Ç‡§ó ‡§Ü‡§£‡§ø ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§® ‡§ß‡•ã‡§∞‡§£‡•á
- **‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§£‡•á**: ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§π‡§æ‡§§‡§æ‡§≥‡§£‡•Ä ‡§Ü‡§£‡§ø ‡§≤‡•â‡§ó‡§ø‡§Ç‡§ó ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®
- **‡§Æ‡•Ç‡§≤‡•ç‡§Ø‡§æ‡§Ç‡§ï‡§®**: ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞‡§≤ ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§®‡§æ‡§Ç‡§Æ‡§ß‡•Ä‡§≤ ‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞-offs

## üèóÔ∏è MCP ‡§∏‡§∞‡•ç‡§µ‡•ç‡§π‡§∞ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§∏‡•ç‡§§‡§∞

‡§Ü‡§Æ‡§ö‡§æ MCP ‡§∏‡§∞‡•ç‡§µ‡•ç‡§π‡§∞ **‡§∏‡•ç‡§§‡§∞‡§ø‡§§ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞** ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§§‡•ã ‡§ú‡•ã ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§µ‡•á‡§ó‡§≥‡§æ ‡§ï‡§∞‡§§‡•ã ‡§Ü‡§£‡§ø ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§∏‡•Å‡§≤‡§≠ ‡§ï‡§∞‡§§‡•ã:

### ‡§∏‡•ç‡§§‡§∞ 1: ‡§™‡•ç‡§∞‡•ã‡§ü‡•ã‡§ï‡•â‡§≤ ‡§∏‡•ç‡§§‡§∞ (FastMCP)
**‡§ú‡§¨‡§æ‡§¨‡§¶‡§æ‡§∞‡•Ä**: MCP ‡§™‡•ç‡§∞‡•ã‡§ü‡•ã‡§ï‡•â‡§≤ ‡§ï‡§Æ‡•ç‡§Ø‡•Å‡§®‡§ø‡§ï‡•á‡§∂‡§® ‡§Ü‡§£‡§ø ‡§Æ‡•á‡§∏‡•á‡§ú ‡§∞‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§π‡§æ‡§§‡§æ‡§≥‡§£‡•á

```python
# FastMCP server setup
from fastmcp import FastMCP

mcp = FastMCP("Zava Retail Analytics")

# Tool registration with type safety
@mcp.tool()
async def execute_sales_query(
    ctx: Context,
    postgresql_query: Annotated[str, Field(description="Well-formed PostgreSQL query")]
) -> str:
    """Execute PostgreSQL queries with Row Level Security."""
    return await query_executor.execute(postgresql_query, ctx)
```

**‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§µ‡•à‡§∂‡§ø‡§∑‡•ç‡§ü‡•ç‡§Ø‡•á**:
- **‡§™‡•ç‡§∞‡•ã‡§ü‡•ã‡§ï‡•â‡§≤ ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§®**: MCP ‡§∏‡•ç‡§™‡•á‡§∏‡§ø‡§´‡§ø‡§ï‡•á‡§∂‡§®‡§ö‡•á ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§®
- **‡§ü‡§æ‡§á‡§™ ‡§∏‡•á‡§´‡•ç‡§ü‡•Ä**: ‡§µ‡§ø‡§®‡§Ç‡§§‡•Ä/‡§™‡•ç‡§∞‡§§‡§ø‡§∏‡§æ‡§¶ ‡§™‡§°‡§§‡§æ‡§≥‡§£‡•Ä‡§∏‡§æ‡§†‡•Ä Pydantic ‡§Æ‡•â‡§°‡•á‡§≤‡•ç‡§∏
- **Async ‡§∏‡§Æ‡§∞‡•ç‡§•‡§®**: ‡§â‡§ö‡•ç‡§ö ‡§è‡§ï‡§§‡•ç‡§∞‡§ø‡§§‡§§‡•á‡§∏‡§æ‡§†‡•Ä ‡§®‡•â‡§®-‡§¨‡•ç‡§≤‡•â‡§ï‡§ø‡§Ç‡§ó I/O
- **‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§π‡§æ‡§§‡§æ‡§≥‡§£‡•Ä**: ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡§ø‡§§ ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§™‡•ç‡§∞‡§§‡§ø‡§∏‡§æ‡§¶

### ‡§∏‡•ç‡§§‡§∞ 2: ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø ‡§≤‡•â‡§ú‡§ø‡§ï ‡§∏‡•ç‡§§‡§∞
**‡§ú‡§¨‡§æ‡§¨‡§¶‡§æ‡§∞‡•Ä**: ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø ‡§®‡§ø‡§Ø‡§Æ ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§£‡•á ‡§Ü‡§£‡§ø ‡§™‡•ç‡§∞‡•ã‡§ü‡•ã‡§ï‡•â‡§≤ ‡§Ü‡§£‡§ø ‡§°‡•á‡§ü‡§æ ‡§∏‡•ç‡§§‡§∞‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø ‡§∏‡§æ‡§ß‡§£‡•á

```python
class SalesAnalyticsService:
    """Business logic for retail analytics operations."""
    
    async def get_store_performance(
        self, 
        store_id: str, 
        time_period: str
    ) -> Dict[str, Any]:
        """Calculate store performance metrics."""
        
        # Validate business rules
        if not self._validate_store_access(store_id):
            raise UnauthorizedError("Access denied for store")
        
        # Coordinate data retrieval
        sales_data = await self.db_provider.get_sales_data(store_id, time_period)
        metrics = self._calculate_metrics(sales_data)
        
        return {
            "store_id": store_id,
            "period": time_period,
            "metrics": metrics,
            "insights": self._generate_insights(metrics)
        }
```

**‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§µ‡•à‡§∂‡§ø‡§∑‡•ç‡§ü‡•ç‡§Ø‡•á**:
- **‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø ‡§®‡§ø‡§Ø‡§Æ ‡§Ö‡§Ç‡§Æ‡§≤‡§¨‡§ú‡§æ‡§µ‡§£‡•Ä**: ‡§∏‡•ç‡§ü‡•ã‡§Ö‡§∞ ‡§™‡•ç‡§∞‡§µ‡•á‡§∂ ‡§™‡§°‡§§‡§æ‡§≥‡§£‡•Ä ‡§Ü‡§£‡§ø ‡§°‡•á‡§ü‡§æ ‡§Ö‡§ñ‡§Ç‡§°‡§§‡§æ
- **‡§∏‡•á‡§µ‡§æ ‡§∏‡§Æ‡§®‡•ç‡§µ‡§Ø**: ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§Ü‡§£‡§ø AI ‡§∏‡•á‡§µ‡§æ‡§Ç‡§Æ‡§ß‡•Ä‡§≤ ‡§ë‡§∞‡•ç‡§ï‡•á‡§∏‡•ç‡§ü‡•ç‡§∞‡•á‡§∂‡§®
- **‡§°‡•á‡§ü‡§æ ‡§∞‡•Ç‡§™‡§æ‡§Ç‡§§‡§∞‡§£**: ‡§ï‡§ö‡•ç‡§ö‡•ç‡§Ø‡§æ ‡§°‡•á‡§ü‡§æ‡§ö‡•á ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø ‡§Ö‡§Ç‡§§‡§∞‡•ç‡§¶‡•É‡§∑‡•ç‡§ü‡•Ä‡§§ ‡§∞‡•Ç‡§™‡§æ‡§Ç‡§§‡§∞
- **‡§ï‡•Ö‡§∂‡§ø‡§Ç‡§ó ‡§ß‡•ã‡§∞‡§£**: ‡§µ‡§æ‡§∞‡§Ç‡§µ‡§æ‡§∞ ‡§ï‡•ç‡§µ‡•á‡§∞‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§Ö‡§®‡•Å‡§ï‡•Ç‡§≤‡§®

### ‡§∏‡•ç‡§§‡§∞ 3: ‡§°‡•á‡§ü‡§æ ‡§™‡•ç‡§∞‡§µ‡•á‡§∂ ‡§∏‡•ç‡§§‡§∞
**‡§ú‡§¨‡§æ‡§¨‡§¶‡§æ‡§∞‡•Ä**: ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡§£‡•á, ‡§ï‡•ç‡§µ‡•á‡§∞‡•Ä ‡§Ö‡§Ç‡§Æ‡§≤‡§¨‡§ú‡§æ‡§µ‡§£‡•Ä ‡§Ü‡§£‡§ø ‡§°‡•á‡§ü‡§æ ‡§Æ‡•Ö‡§™‡§ø‡§Ç‡§ó

```python
class PostgreSQLProvider:
    """Data access layer for PostgreSQL operations."""
    
    def __init__(self, connection_config: Dict[str, Any]):
        self.connection_pool: Optional[Pool] = None
        self.config = connection_config
    
    async def execute_query(
        self, 
        query: str, 
        rls_user_id: str
    ) -> List[Dict[str, Any]]:
        """Execute query with RLS context."""
        
        async with self.connection_pool.acquire() as conn:
            # Set RLS context
            await conn.execute(
                "SELECT set_config('app.current_rls_user_id', $1, false)",
                rls_user_id
            )
            
            # Execute query with timeout
            try:
                rows = await asyncio.wait_for(
                    conn.fetch(query),
                    timeout=30.0
                )
                return [dict(row) for row in rows]
            except asyncio.TimeoutError:
                raise QueryTimeoutError("Query execution exceeded timeout")
```

**‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§µ‡•à‡§∂‡§ø‡§∑‡•ç‡§ü‡•ç‡§Ø‡•á**:
- **‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§™‡•Ç‡§≤‡§ø‡§Ç‡§ó**: ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§® ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ
- **‡§ü‡•ç‡§∞‡§æ‡§®‡•ç‡§ù‡•Ö‡§ï‡•ç‡§∂‡§® ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§®**: ACID ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§® ‡§Ü‡§£‡§ø ‡§∞‡•ã‡§≤‡§¨‡•Ö‡§ï ‡§π‡§æ‡§§‡§æ‡§≥‡§£‡•Ä
- **‡§ï‡•ç‡§µ‡•á‡§∞‡•Ä ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§Ø‡§ù‡•á‡§∂‡§®**: ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§®‡§ø‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§Ü‡§£‡§ø ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§Ø‡§ù‡•á‡§∂‡§®
- **RLS ‡§á‡§Ç‡§ü‡§ø‡§ó‡•ç‡§∞‡•á‡§∂‡§®**: ‡§∞‡•ã-‡§≤‡•á‡§µ‡•ç‡§π‡§≤ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§®

### ‡§∏‡•ç‡§§‡§∞ 4: ‡§™‡§æ‡§Ø‡§æ‡§≠‡•Ç‡§§ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§∏‡•ç‡§§‡§∞
**‡§ú‡§¨‡§æ‡§¨‡§¶‡§æ‡§∞‡•Ä**: ‡§≤‡•â‡§ó‡§ø‡§Ç‡§ó, ‡§Æ‡•â‡§®‡§ø‡§ü‡§∞‡§ø‡§Ç‡§ó ‡§Ü‡§£‡§ø ‡§ï‡•â‡§®‡•ç‡§´‡§ø‡§ó‡§∞‡•á‡§∂‡§® ‡§Ø‡§æ‡§∏‡§æ‡§∞‡§ñ‡•ç‡§Ø‡§æ ‡§ï‡•ç‡§∞‡•â‡§∏-‡§ï‡§ü‡§ø‡§Ç‡§ó ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§π‡§æ‡§§‡§æ‡§≥‡§£‡•á

```python
class InfrastructureManager:
    """Infrastructure concerns management."""
    
    def __init__(self):
        self.logger = self._setup_logging()
        self.metrics = self._setup_metrics()
        self.config = self._load_configuration()
    
    def _setup_logging(self) -> Logger:
        """Configure structured logging."""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('mcp_server.log')
            ]
        )
        return logging.getLogger(__name__)
    
    async def track_query_execution(
        self, 
        query_type: str, 
        duration: float, 
        success: bool
    ):
        """Track query performance metrics."""
        self.metrics.counter('query_total').labels(
            type=query_type,
            status='success' if success else 'error'
        ).inc()
        
        self.metrics.histogram('query_duration').labels(
            type=query_type
        ).observe(duration)
```

## üóÑÔ∏è ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§°‡§ø‡§ù‡§æ‡§á‡§® ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏

‡§Ü‡§Æ‡§ö‡§æ PostgreSQL ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡§æ ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§ü‡•á‡§®‡§Ç‡§ü MCP ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§Ö‡§®‡•á‡§ï ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§æ‡§ö‡•á ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏ ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§§‡•ã:

### 1. ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§ü‡•á‡§®‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡§æ ‡§°‡§ø‡§ù‡§æ‡§á‡§®

```sql
-- Core retail entities with store-based partitioning
CREATE TABLE retail.stores (
    store_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    location VARCHAR(200) NOT NULL,
    manager_id UUID NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.customers (
    customer_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    store_id UUID REFERENCES retail.stores(store_id),
    first_name VARCHAR(50) NOT NULL,
    last_name VARCHAR(50) NOT NULL,
    email VARCHAR(100) UNIQUE,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.orders (
    order_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    customer_id UUID REFERENCES retail.customers(customer_id),
    store_id UUID REFERENCES retail.stores(store_id),
    order_date TIMESTAMP DEFAULT NOW(),
    total_amount DECIMAL(10,2) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending'
);
```

**‡§°‡§ø‡§ù‡§æ‡§á‡§® ‡§§‡§§‡•ç‡§§‡•ç‡§µ‡•á**:
- **‡§´‡•â‡§∞‡•á‡§® ‡§ï‡•Ä ‡§∏‡•Å‡§∏‡§Ç‡§ó‡§§‡§§‡§æ**: ‡§ü‡•á‡§¨‡§≤‡•ç‡§∏‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§°‡•á‡§ü‡§æ ‡§Ö‡§ñ‡§Ç‡§°‡§§‡§æ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§æ
- **‡§∏‡•ç‡§ü‡•ã‡§Ö‡§∞ ID ‡§™‡•ç‡§∞‡§∏‡§æ‡§∞**: ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§µ‡•ç‡§Ø‡§µ‡§π‡§æ‡§∞‡§æ‡§§‡•ç‡§Æ‡§ï ‡§ü‡•á‡§¨‡§≤‡§Æ‡§ß‡•ç‡§Ø‡•á store_id ‡§∏‡§Æ‡§æ‡§µ‡§ø‡§∑‡•ç‡§ü ‡§Ü‡§π‡•á
- **UUID ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§ï‡•Ä**: ‡§µ‡§ø‡§§‡§∞‡§ø‡§§ ‡§™‡•ç‡§∞‡§£‡§æ‡§≤‡•Ä‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§ú‡§æ‡§ó‡§§‡§ø‡§ï ‡§∏‡•ç‡§§‡§∞‡§æ‡§µ‡§∞ ‡§Ö‡§¶‡•ç‡§µ‡§ø‡§§‡•Ä‡§Ø ‡§ì‡§≥‡§ñ‡§™‡§§‡•ç‡§∞‡•á
- **‡§ü‡§æ‡§á‡§Æ‡§∏‡•ç‡§ü‡•Ö‡§Æ‡•ç‡§™ ‡§ü‡•ç‡§∞‡•Ö‡§ï‡§ø‡§Ç‡§ó**: ‡§∏‡§∞‡•ç‡§µ ‡§°‡•á‡§ü‡§æ ‡§¨‡§¶‡§≤‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§ë‡§°‡§ø‡§ü ‡§ü‡•ç‡§∞‡•á‡§≤

### 2. ‡§∞‡•ã ‡§≤‡•á‡§µ‡•ç‡§π‡§≤ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§Ö‡§Ç‡§Æ‡§≤‡§¨‡§ú‡§æ‡§µ‡§£‡•Ä

```sql
-- Enable RLS on multi-tenant tables
ALTER TABLE retail.customers ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.orders ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.order_items ENABLE ROW LEVEL SECURITY;

-- Store manager can only see their store's data
CREATE POLICY store_manager_customers ON retail.customers
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

CREATE POLICY store_manager_orders ON retail.orders
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

-- Regional managers see multiple stores
CREATE POLICY regional_manager_orders ON retail.orders
    FOR ALL TO regional_managers
    USING (store_id = ANY(get_user_store_list()));

-- Support function for RLS context
CREATE OR REPLACE FUNCTION get_current_user_store()
RETURNS UUID AS $$
BEGIN
    RETURN current_setting('app.current_rls_user_id')::UUID;
EXCEPTION WHEN OTHERS THEN
    RETURN '00000000-0000-0000-0000-000000000000'::UUID;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

**RLS ‡§´‡§æ‡§Ø‡§¶‡•á**:
- **‡§∏‡•ç‡§µ‡§Ø‡§Ç‡§ö‡§≤‡§ø‡§§ ‡§´‡§ø‡§≤‡•ç‡§ü‡§∞‡§ø‡§Ç‡§ó**: ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§°‡•á‡§ü‡§æ ‡§µ‡•á‡§ó‡§≥‡•á‡§™‡§£‡§æ ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§§‡•ã
- **‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§∏‡§æ‡§ß‡•á‡§™‡§£‡§æ**: ‡§ú‡§ü‡§ø‡§≤ WHERE ‡§ï‡•ç‡§≤‡•â‡§ú‡§ö‡•Ä ‡§ó‡§∞‡§ú ‡§®‡§æ‡§π‡•Ä
- **‡§°‡§ø‡§´‡•â‡§≤‡•ç‡§ü‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ**: ‡§ö‡•Å‡§ï‡•Ä‡§ö‡§æ ‡§°‡•á‡§ü‡§æ ‡§Ö‡§™‡§ò‡§æ‡§§‡§æ‡§®‡•á ‡§™‡•ç‡§∞‡§µ‡•á‡§∂ ‡§ï‡§∞‡§£‡•á ‡§Ö‡§∂‡§ï‡•ç‡§Ø
- **‡§ë‡§°‡§ø‡§ü ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§®**: ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§°‡•á‡§ü‡§æ ‡§™‡•ç‡§∞‡§µ‡•á‡§∂ ‡§∏‡•Ä‡§Æ‡§æ

### 3. ‡§µ‡•ç‡§π‡•á‡§ï‡•ç‡§ü‡§∞ ‡§∂‡•ã‡§ß ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡§æ

```sql
-- Product embeddings for semantic search
CREATE TABLE retail.product_description_embeddings (
    product_id UUID PRIMARY KEY REFERENCES retail.products(product_id),
    description_embedding vector(1536),
    last_updated TIMESTAMP DEFAULT NOW()
);

-- Optimize vector similarity search
CREATE INDEX idx_product_embeddings_vector 
ON retail.product_description_embeddings 
USING ivfflat (description_embedding vector_cosine_ops);

-- Semantic search function
CREATE OR REPLACE FUNCTION search_products_by_description(
    query_embedding vector(1536),
    similarity_threshold FLOAT DEFAULT 0.7,
    max_results INTEGER DEFAULT 20
)
RETURNS TABLE(
    product_id UUID,
    name VARCHAR,
    description TEXT,
    similarity_score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        p.product_id,
        p.name,
        p.description,
        (1 - (pde.description_embedding <=> query_embedding)) AS similarity_score
    FROM retail.products p
    JOIN retail.product_description_embeddings pde ON p.product_id = pde.product_id
    WHERE (pde.description_embedding <=> query_embedding) <= (1 - similarity_threshold)
    ORDER BY similarity_score DESC
    LIMIT max_results;
END;
$$ LANGUAGE plpgsql;
```

## üîå ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§® ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏

MCP ‡§∏‡§∞‡•ç‡§µ‡•ç‡§π‡§∞ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§§‡•á‡§∏‡§æ‡§†‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§® ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§æ‡§ö‡•á ‡§Ü‡§π‡•á:

### ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§™‡•Ç‡§≤ ‡§ï‡•â‡§®‡•ç‡§´‡§ø‡§ó‡§∞‡•á‡§∂‡§®

```python
class ConnectionPoolManager:
    """Manages PostgreSQL connection pools."""
    
    async def create_pool(self) -> Pool:
        """Create optimized connection pool."""
        return await asyncpg.create_pool(
            host=self.config.db_host,
            port=self.config.db_port,
            database=self.config.db_name,
            user=self.config.db_user,
            password=self.config.db_password,
            
            # Pool configuration
            min_size=2,          # Minimum connections
            max_size=10,         # Maximum connections
            max_inactive_connection_lifetime=300,  # 5 minutes
            
            # Query configuration
            command_timeout=30,   # Query timeout
            server_settings={
                "application_name": "zava-mcp-server",
                "jit": "off",          # Disable JIT for stability
                "work_mem": "4MB",     # Limit work memory
                "statement_timeout": "30s"
            }
        )
    
    async def execute_with_retry(
        self, 
        query: str, 
        params: Tuple = None,
        max_retries: int = 3
    ) -> List[Dict[str, Any]]:
        """Execute query with automatic retry logic."""
        
        for attempt in range(max_retries):
            try:
                async with self.pool.acquire() as conn:
                    if params:
                        rows = await conn.fetch(query, *params)
                    else:
                        rows = await conn.fetch(query)
                    return [dict(row) for row in rows]
                    
            except (ConnectionError, InterfaceError) as e:
                if attempt == max_retries - 1:
                    raise
                
                # Exponential backoff
                await asyncio.sleep(2 ** attempt)
                logger.warning(f"Database connection failed, retrying ({attempt + 1}/{max_retries})")
```

### ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§ú‡•Ä‡§µ‡§®‡§ö‡§ï‡•ç‡§∞ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§®

```python
class MCPServerManager:
    """Manages MCP server lifecycle and resources."""
    
    async def startup(self):
        """Initialize server resources."""
        # Create database connection pool
        self.db_pool = await self.pool_manager.create_pool()
        
        # Initialize AI services
        self.ai_client = await self.create_ai_client()
        
        # Setup monitoring
        self.metrics_collector = MetricsCollector()
        
        logger.info("MCP server startup complete")
    
    async def shutdown(self):
        """Cleanup server resources."""
        try:
            # Close database connections
            if self.db_pool:
                await self.db_pool.close()
            
            # Cleanup AI client
            if self.ai_client:
                await self.ai_client.close()
            
            # Flush metrics
            await self.metrics_collector.flush()
            
            logger.info("MCP server shutdown complete")
            
        except Exception as e:
            logger.error(f"Error during shutdown: {e}")
    
    async def health_check(self) -> Dict[str, str]:
        """Verify server health status."""
        status = {}
        
        # Check database connection
        try:
            async with self.db_pool.acquire() as conn:
                await conn.fetchval("SELECT 1")
            status["database"] = "healthy"
        except Exception as e:
            status["database"] = f"unhealthy: {e}"
        
        # Check AI service
        try:
            await self.ai_client.health_check()
            status["ai_service"] = "healthy"
        except Exception as e:
            status["ai_service"] = f"unhealthy: {e}"
        
        return status
```

## üõ°Ô∏è ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§π‡§æ‡§§‡§æ‡§≥‡§£‡•Ä ‡§Ü‡§£‡§ø ‡§≤‡§µ‡§ö‡§ø‡§ï‡§§‡§æ ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏

‡§Æ‡§ú‡§¨‡•Ç‡§§ ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§π‡§æ‡§§‡§æ‡§≥‡§£‡•Ä MCP ‡§∏‡§∞‡•ç‡§µ‡•ç‡§π‡§∞‡§ö‡•Ä ‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏‡§æ‡§∞‡•ç‡§π‡§§‡§æ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§§‡•á:

### ‡§∂‡•ç‡§∞‡•á‡§£‡•Ä‡§¨‡§¶‡•ç‡§ß ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞

```python
class MCPError(Exception):
    """Base MCP server error."""
    def __init__(self, message: str, error_code: str = "MCP_ERROR"):
        self.message = message
        self.error_code = error_code
        super().__init__(message)

class DatabaseError(MCPError):
    """Database operation errors."""
    def __init__(self, message: str, query: str = None):
        super().__init__(message, "DATABASE_ERROR")
        self.query = query

class AuthorizationError(MCPError):
    """Access control errors."""
    def __init__(self, message: str, user_id: str = None):
        super().__init__(message, "AUTHORIZATION_ERROR")
        self.user_id = user_id

class QueryTimeoutError(DatabaseError):
    """Query execution timeout."""
    def __init__(self, query: str):
        super().__init__(f"Query timeout: {query[:100]}...", query)
        self.error_code = "QUERY_TIMEOUT"

class ValidationError(MCPError):
    """Input validation errors."""
    def __init__(self, field: str, value: Any, constraint: str):
        message = f"Validation failed for {field}: {constraint}"
        super().__init__(message, "VALIDATION_ERROR")
        self.field = field
        self.value = value
```

### ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§π‡§æ‡§§‡§æ‡§≥‡§£‡•Ä ‡§Æ‡§ø‡§°‡§≤‡§µ‡•á‡§Ö‡§∞

```python
@contextmanager
async def error_handling_context(operation_name: str, user_id: str = None):
    """Centralized error handling for operations."""
    start_time = time.time()
    
    try:
        yield
        
        # Success metrics
        duration = time.time() - start_time
        metrics.operation_success.labels(operation=operation_name).inc()
        metrics.operation_duration.labels(operation=operation_name).observe(duration)
        
    except ValidationError as e:
        logger.warning(f"Validation error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "validation",
            "field": e.field
        })
        metrics.operation_error.labels(operation=operation_name, type="validation").inc()
        raise
        
    except AuthorizationError as e:
        logger.warning(f"Authorization error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "authorization"
        })
        metrics.operation_error.labels(operation=operation_name, type="authorization").inc()
        raise
        
    except DatabaseError as e:
        logger.error(f"Database error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "database",
            "query": e.query[:100] if e.query else None
        })
        metrics.operation_error.labels(operation=operation_name, type="database").inc()
        raise
        
    except Exception as e:
        logger.error(f"Unexpected error in {operation_name}: {str(e)}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "unexpected"
        }, exc_info=True)
        metrics.operation_error.labels(operation=operation_name, type="unexpected").inc()
        raise MCPError(f"Internal server error in {operation_name}")
```

## üìä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§Ø‡§ù‡•á‡§∂‡§® ‡§ß‡•ã‡§∞‡§£‡•á

### ‡§ï‡•ç‡§µ‡•á‡§∞‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§®‡§ø‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£

```python
class QueryPerformanceMonitor:
    """Monitor and optimize query performance."""
    
    def __init__(self):
        self.slow_query_threshold = 1.0  # seconds
        self.query_stats = defaultdict(list)
    
    @contextmanager
    async def monitor_query(self, query: str, operation_type: str = "unknown"):
        """Monitor query execution time and performance."""
        start_time = time.time()
        query_hash = hashlib.md5(query.encode()).hexdigest()[:8]
        
        try:
            yield
            
            duration = time.time() - start_time
            
            # Record performance metrics
            self.query_stats[operation_type].append(duration)
            
            # Log slow queries
            if duration > self.slow_query_threshold:
                logger.warning(f"Slow query detected", extra={
                    "query_hash": query_hash,
                    "duration": duration,
                    "operation_type": operation_type,
                    "query": query[:200]
                })
            
            # Update metrics
            metrics.query_duration.labels(type=operation_type).observe(duration)
            
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Query failed", extra={
                "query_hash": query_hash,
                "duration": duration,
                "operation_type": operation_type,
                "error": str(e)
            })
            raise
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Generate performance summary report."""
        summary = {}
        
        for operation_type, durations in self.query_stats.items():
            if durations:
                summary[operation_type] = {
                    "count": len(durations),
                    "avg_duration": sum(durations) / len(durations),
                    "max_duration": max(durations),
                    "min_duration": min(durations),
                    "slow_queries": len([d for d in durations if d > self.slow_query_threshold])
                }
        
        return summary
```

### ‡§ï‡•Ö‡§∂‡§ø‡§Ç‡§ó ‡§ß‡•ã‡§∞‡§£

```python
class QueryCache:
    """Intelligent query result caching."""
    
    def __init__(self, redis_url: str = None):
        self.cache = {}  # In-memory fallback
        self.redis_client = redis.Redis.from_url(redis_url) if redis_url else None
        self.cache_ttl = 300  # 5 minutes default
    
    async def get_cached_result(
        self, 
        cache_key: str, 
        query_func: Callable,
        ttl: int = None
    ) -> Any:
        """Get result from cache or execute query."""
        ttl = ttl or self.cache_ttl
        
        # Try cache first
        cached_result = await self._get_from_cache(cache_key)
        if cached_result is not None:
            metrics.cache_hit.labels(type="query").inc()
            return cached_result
        
        # Execute query
        metrics.cache_miss.labels(type="query").inc()
        result = await query_func()
        
        # Cache result
        await self._set_in_cache(cache_key, result, ttl)
        
        return result
    
    def _generate_cache_key(self, query: str, user_context: str) -> str:
        """Generate consistent cache key."""
        key_data = f"{query}:{user_context}"
        return hashlib.sha256(key_data.encode()).hexdigest()
```

## üéØ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§Æ‡•Å‡§¶‡•ç‡§¶‡•á

‡§π‡§æ ‡§Æ‡•â‡§°‡•ç‡§Ø‡•Ç‡§≤ ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡•á‡§≤‡•ç‡§Ø‡§æ‡§®‡§Ç‡§§‡§∞, ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§∏‡§Æ‡§ú‡•Ç‡§® ‡§ò‡•ç‡§Ø‡§æ‡§≤:

‚úÖ **‡§∏‡•ç‡§§‡§∞‡§ø‡§§ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞**: MCP ‡§∏‡§∞‡•ç‡§µ‡•ç‡§π‡§∞ ‡§°‡§ø‡§ù‡§æ‡§á‡§®‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§µ‡•á‡§ó‡§≥‡•á ‡§ï‡§∏‡•á ‡§ï‡§∞‡§æ‡§Ø‡§ö‡•á  
‚úÖ **‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏**: ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§ü‡•á‡§®‡§Ç‡§ü ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡§æ ‡§°‡§ø‡§ù‡§æ‡§á‡§® ‡§Ü‡§£‡§ø RLS ‡§Ö‡§Ç‡§Æ‡§≤‡§¨‡§ú‡§æ‡§µ‡§£‡•Ä  
‚úÖ **‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§®**: ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ ‡§™‡•Ç‡§≤‡§ø‡§Ç‡§ó ‡§Ü‡§£‡§ø ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§ú‡•Ä‡§µ‡§®‡§ö‡§ï‡•ç‡§∞  
‚úÖ **‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§π‡§æ‡§§‡§æ‡§≥‡§£‡•Ä**: ‡§∂‡•ç‡§∞‡•á‡§£‡•Ä‡§¨‡§¶‡•ç‡§ß ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§Ü‡§£‡§ø ‡§≤‡§µ‡§ö‡§ø‡§ï‡§§‡§æ ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏  
‚úÖ **‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§Ø‡§ù‡•á‡§∂‡§®**: ‡§Æ‡•â‡§®‡§ø‡§ü‡§∞‡§ø‡§Ç‡§ó, ‡§ï‡•Ö‡§∂‡§ø‡§Ç‡§ó ‡§Ü‡§£‡§ø ‡§ï‡•ç‡§µ‡•á‡§∞‡•Ä ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§Ø‡§ù‡•á‡§∂‡§®  
‚úÖ **‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§§‡§Ø‡§æ‡§∞‡•Ä**: ‡§™‡§æ‡§Ø‡§æ‡§≠‡•Ç‡§§ ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§Ü‡§£‡§ø ‡§ë‡§™‡§∞‡•á‡§∂‡§®‡§≤ ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏  

## üöÄ ‡§™‡•Å‡§¢‡•á ‡§ï‡§æ‡§Ø

**[‡§Æ‡•â‡§°‡•ç‡§Ø‡•Ç‡§≤ 02: ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§Ü‡§£‡§ø ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§ü‡•á‡§®‡§®‡•ç‡§∏‡•Ä](../02-Security/README.md)** ‡§∏‡§π ‡§™‡•Å‡§¢‡•á ‡§ú‡§æ:

- ‡§∞‡•ã ‡§≤‡•á‡§µ‡•ç‡§π‡§≤ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§Ö‡§Ç‡§Æ‡§≤‡§¨‡§ú‡§æ‡§µ‡§£‡•Ä ‡§§‡§™‡§∂‡•Ä‡§≤
- ‡§™‡•ç‡§∞‡§Æ‡§æ‡§£‡•Ä‡§ï‡§∞‡§£ ‡§Ü‡§£‡§ø ‡§Ö‡§ß‡§ø‡§ï‡•É‡§§‡§§‡§æ ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏
- ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§ü‡•á‡§®‡§Ç‡§ü ‡§°‡•á‡§ü‡§æ ‡§µ‡•á‡§ó‡§≥‡•á‡§™‡§£‡§æ ‡§ß‡•ã‡§∞‡§£‡•á
- ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ë‡§°‡§ø‡§ü ‡§Ü‡§£‡§ø ‡§Ö‡§®‡•Å‡§™‡§æ‡§≤‡§® ‡§µ‡§ø‡§ö‡§æ‡§∞

## üìö ‡§Ö‡§§‡§ø‡§∞‡§ø‡§ï‡•ç‡§§ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®‡•á

### ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏
- [Python ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ï‡•ç‡§≤‡•Ä‡§® ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞](https://github.com/cosmic-python/code) - Python ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞‡§≤ ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏
- [‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§°‡§ø‡§ù‡§æ‡§á‡§® ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏](https://en.wikipedia.org/wiki/Database_design) - ‡§∞‡§ø‡§≤‡•á‡§∂‡§®‡§≤ ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§°‡§ø‡§ù‡§æ‡§á‡§® ‡§§‡§§‡•ç‡§§‡•ç‡§µ‡•á
- [‡§Æ‡§æ‡§Ø‡§ï‡•ç‡§∞‡•ã‡§∏‡§∞‡•ç‡§µ‡•ç‡§π‡§ø‡§∏‡•á‡§∏ ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏](https://microservices.io/patterns/) - ‡§∏‡•á‡§µ‡§æ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞ ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏

### PostgreSQL ‡§™‡•ç‡§∞‡§ó‡§§ ‡§µ‡§ø‡§∑‡§Ø
- [PostgreSQL ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§ü‡•ç‡§Ø‡•Ç‡§®‡§ø‡§Ç‡§ó](https://wiki.postgresql.org/wiki/Performance_Optimization) - ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏ ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§Ø‡§ù‡•á‡§∂‡§® ‡§Æ‡§æ‡§∞‡•ç‡§ó‡§¶‡§∞‡•ç‡§∂‡§ï
- [‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§™‡•Ç‡§≤‡§ø‡§Ç‡§ó ‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§™‡§¶‡•ç‡§ß‡§§‡•Ä](https://www.postgresql.org/docs/current/runtime-config-connection.html) - ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§®
- [‡§ï‡•ç‡§µ‡•á‡§∞‡•Ä ‡§™‡•ç‡§≤‡•Ö‡§®‡§ø‡§Ç‡§ó ‡§Ü‡§£‡§ø ‡§ë‡§™‡•ç‡§ü‡§ø‡§Æ‡§æ‡§Ø‡§ù‡•á‡§∂‡§®](https://www.postgresql.org/docs/current/planner-optimizer.html) - ‡§ï‡•ç‡§µ‡•á‡§∞‡•Ä ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ

### Python Async ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏
- [AsyncIO ‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§™‡§¶‡•ç‡§ß‡§§‡•Ä](https://docs.python.org/3/library/asyncio.html) - Async ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ‡§ø‡§Ç‡§ó ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏
- [FastAPI ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞](https://fastapi.tiangolo.com/advanced/) - ‡§Ü‡§ß‡•Å‡§®‡§ø‡§ï Python ‡§µ‡•á‡§¨ ‡§Ü‡§∞‡•ç‡§ï‡§ø‡§ü‡•á‡§ï‡•ç‡§ö‡§∞
- [Pydantic ‡§Æ‡•â‡§°‡•á‡§≤‡•ç‡§∏](https://pydantic-docs.helpmanual.io/) - ‡§°‡•á‡§ü‡§æ ‡§™‡§°‡§§‡§æ‡§≥‡§£‡•Ä ‡§Ü‡§£‡§ø ‡§∏‡§ø‡§∞‡•Ä‡§Ø‡§≤‡§æ‡§Ø‡§ù‡•á‡§∂‡§®

---

**‡§™‡•Å‡§¢‡•á**: ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§™‡•Ö‡§ü‡§∞‡•ç‡§®‡•ç‡§∏ ‡§è‡§ï‡•ç‡§∏‡§™‡•ç‡§≤‡•ã‡§∞ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§§‡§Ø‡§æ‡§∞ ‡§Ü‡§π‡§æ‡§§? [‡§Æ‡•â‡§°‡•ç‡§Ø‡•Ç‡§≤ 02: ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§Ü‡§£‡§ø ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§ü‡•á‡§®‡§®‡•ç‡§∏‡•Ä](../02-Security/README.md) ‡§∏‡§π ‡§™‡•Å‡§¢‡•á ‡§ú‡§æ

---

**‡§Ö‡§∏‡•ç‡§µ‡•Ä‡§ï‡§∞‡§£**:  
‡§π‡§æ ‡§¶‡§∏‡•ç‡§§‡§ê‡§µ‡§ú AI ‡§≠‡§æ‡§∑‡§æ‡§Ç‡§§‡§∞ ‡§∏‡•á‡§µ‡§æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡§µ‡§æ‡§™‡§∞‡•Ç‡§® ‡§≠‡§æ‡§∑‡§æ‡§Ç‡§§‡§∞‡§ø‡§§ ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Ü‡§≤‡§æ ‡§Ü‡§π‡•á. ‡§Ü‡§Æ‡•ç‡§π‡•Ä ‡§Ö‡§ö‡•Ç‡§ï‡§§‡•á‡§∏‡§æ‡§†‡•Ä ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§®‡§∂‡•Ä‡§≤ ‡§Ö‡§∏‡§≤‡•ã ‡§§‡§∞‡•Ä ‡§ï‡•É‡§™‡§Ø‡§æ ‡§≤‡§ï‡•ç‡§∑‡§æ‡§§ ‡§†‡•á‡§µ‡§æ ‡§ï‡•Ä ‡§∏‡•ç‡§µ‡§Ø‡§Ç‡§ö‡§≤‡§ø‡§§ ‡§≠‡§æ‡§∑‡§æ‡§Ç‡§§‡§∞‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§Ö‡§ö‡•Ç‡§ï‡§§‡•á‡§ö‡§æ ‡§Ö‡§≠‡§æ‡§µ ‡§Ö‡§∏‡•Ç ‡§∂‡§ï‡§§‡•ã. ‡§Æ‡•Ç‡§≥ ‡§≠‡§æ‡§∑‡•á‡§§‡•Ä‡§≤ ‡§¶‡§∏‡•ç‡§§‡§ê‡§µ‡§ú ‡§π‡§æ ‡§Ö‡§ß‡§ø‡§ï‡•É‡§§ ‡§∏‡•ç‡§∞‡•ã‡§§ ‡§Æ‡§æ‡§®‡§≤‡§æ ‡§ú‡§æ‡§µ‡§æ. ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä‡§∏‡§æ‡§†‡•Ä ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§Æ‡§æ‡§®‡§µ‡•Ä ‡§≠‡§æ‡§∑‡§æ‡§Ç‡§§‡§∞‡§æ‡§ö‡•Ä ‡§∂‡§ø‡§´‡§æ‡§∞‡§∏ ‡§ï‡•á‡§≤‡•Ä ‡§ú‡§æ‡§§‡•á. ‡§Ø‡§æ ‡§≠‡§æ‡§∑‡§æ‡§Ç‡§§‡§∞‡§æ‡§ö‡§æ ‡§µ‡§æ‡§™‡§∞ ‡§ï‡§∞‡•Ç‡§® ‡§â‡§¶‡•ç‡§≠‡§µ‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§ï‡•ã‡§£‡§§‡•ç‡§Ø‡§æ‡§π‡•Ä ‡§ó‡•à‡§∞‡§∏‡§Æ‡§ú ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§ö‡•Å‡§ï‡•Ä‡§ö‡•ç‡§Ø‡§æ ‡§Ö‡§∞‡•ç‡§•‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ü‡§Æ‡•ç‡§π‡•Ä ‡§ú‡§¨‡§æ‡§¨‡§¶‡§æ‡§∞ ‡§∞‡§æ‡§π‡§£‡§æ‡§∞ ‡§®‡§æ‡§π‡•Ä.