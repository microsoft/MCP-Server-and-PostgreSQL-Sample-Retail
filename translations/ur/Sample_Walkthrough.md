<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "c86955fe1dbaafcb4540d8875649e2f5",
  "translation_date": "2025-09-29T18:43:21+00:00",
  "source_file": "Sample_Walkthrough.md",
  "language_code": "ur"
}
-->
# MCP Ø³Ø±ÙˆØ± Ø§ÙˆØ± PostgreSQL Ù†Ù…ÙˆÙ†Û - Ù…Ú©Ù…Ù„ Ø±ÛÙ†Ù…Ø§Ø¦ÛŒ

## ÙÛØ±Ø³Øª
1. [Ø¬Ø§Ø¦Ø²Û](../..)
2. [Ù…Ø¹Ù…Ø§Ø±ÛŒ Ú©ÛŒ ØªÙØµÛŒÙ„](../..)
3. [Ø­Ù„ Ú©ÛŒ ØªØ¹Ù…ÛŒØ±](../..)
4. [Ø§Ø¬Ø²Ø§Ø¡ Ú©ÛŒ ØªÙØµÛŒÙ„](../..)
5. [ØªØ¹ÛŒÙ†Ø§ØªÛŒ Ú¯Ø§Ø¦ÛŒÚˆ](../..)
6. [Ø­Ù„ Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„](../..)
7. [Ø¬Ø¯ÛŒØ¯ Ø®ØµÙˆØµÛŒØ§Øª](../..)
8. [Ù…Ø³Ø§Ø¦Ù„ Ú©Ø§ Ø­Ù„](../..)
9. [Ø¨ÛØªØ±ÛŒÙ† Ø·Ø±ÛŒÙ‚Û’](../..)

## Ø¬Ø§Ø¦Ø²Û

ÛŒÛ Ø±ÛÙ†Ù…Ø§Ø¦ÛŒ ÙˆØ¶Ø§Ø­Øª Ú©Ø±ØªÛŒ ÛÛ’ Ú©Û Ú©Ø³ Ø·Ø±Ø­ Ø§ÛŒÚ© Ù¾Ø±ÙˆÚˆÚ©Ø´Ù† Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø± **Model Context Protocol (MCP) Ø³Ø±ÙˆØ±** Ø¨Ù†Ø§ÛŒØ§ Ø¬Ø§Ø¦Û’ Ø¬Ùˆ PostgreSQL Ø§ÙˆØ± Azure AI Ø®Ø¯Ù…Ø§Øª Ú©Û’ Ø³Ø§ØªÚ¾ Ù…Ø±Ø¨ÙˆØ· ÛÙˆÛ” ÛŒÛ Ù†Ù…ÙˆÙ†Û Ø§Ù†Ù¹Ø±Ù¾Ø±Ø§Ø¦Ø² Ú¯Ø±ÛŒÚˆ Ù¾ÛŒÙ¹Ø±Ù†Ø² Ø¬ÛŒØ³Û’ Row Level SecurityØŒ Ø³ÛŒÙ…ÛŒÙ†Ù¹Ú© Ø³Ø±Ú†ØŒ Ø§ÙˆØ± Ù…Ù„Ù¹ÛŒ Ù¹ÛŒÙ†Ù†Ù¹ ÚˆÛŒÙ¹Ø§ Ø§ÛŒÚ©Ø³ÛŒØ³ Ú©Ùˆ Ø¸Ø§ÛØ± Ú©Ø±ØªØ§ ÛÛ’Û”

### Ø¢Ù¾ Ú©ÛŒØ§ Ø³ÛŒÚ©Ú¾ÛŒÚº Ú¯Û’
- MCP Ø³Ø±ÙˆØ± Ú©Ùˆ ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù† Ú©Û’ Ø³Ø§ØªÚ¾ Ú©ÛŒØ³Û’ ÚˆÛŒØ²Ø§Ø¦Ù† Ú©Ø±ÛŒÚº
- Ù…Ù„Ù¹ÛŒ Ù¹ÛŒÙ†Ù†Ù¹ Ù…Ù†Ø¸Ø±Ù†Ø§Ù…ÙˆÚº Ú©Û’ Ù„ÛŒÛ’ Row Level Security Ù†Ø§ÙØ° Ú©Ø±Ù†Ø§
- Azure OpenAI Ø§ÛŒÙ…Ø¨ÛŒÚˆÙ†Ú¯Ø² Ú©Û’ Ø³Ø§ØªÚ¾ Ø³ÛŒÙ…ÛŒÙ†Ù¹Ú© Ø³Ø±Ú† Ø¨Ù†Ø§Ù†Ø§
- Docker Ù¾Ø± Ù…Ø¨Ù†ÛŒ ØªØ±Ù‚ÛŒØ§ØªÛŒ Ù…Ø§Ø­ÙˆÙ„ Ø¨Ù†Ø§Ù†Ø§
- Bicep Ù¹ÛŒÙ…Ù¾Ù„ÛŒÙ¹Ø³ Ú©Û’ Ø³Ø§ØªÚ¾ Azure Ø§Ù†ÙØ±Ø§Ø³Ù¹Ø±Ú©Ú†Ø± ØªØ¹ÛŒÙ†Ø§Øª Ú©Ø±Ù†Ø§
- VS Code Ú©Û’ Ø³Ø§ØªÚ¾ AI Ù¾Ø§ÙˆØ±Úˆ ØªØ¬Ø²ÛŒØ§Øª Ú©Ùˆ Ù…Ø±Ø¨ÙˆØ· Ú©Ø±Ù†Ø§

### Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ø´Ø¯Û Ù¹ÛŒÚ©Ù†Ø§Ù„ÙˆØ¬ÛŒØ²
- **MCP Protocol**: AI Ù¹ÙˆÙ„ Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù† Ú©Û’ Ù„ÛŒÛ’ Model Context Protocol
- **FastMCP**: Ø¬Ø¯ÛŒØ¯ Python MCP Ø³Ø±ÙˆØ± ÙØ±ÛŒÙ… ÙˆØ±Ú©
- **PostgreSQL**: pgvector Ø§ÛŒÚ©Ø³Ù¹ÛŒÙ†Ø´Ù† Ú©Û’ Ø³Ø§ØªÚ¾ ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø³ÛŒÙ…ÛŒÙ†Ù¹Ú© Ø³Ø±Ú† Ú©Û’ Ù„ÛŒÛ’
- **Azure OpenAI**: Ù¹ÛŒÚ©Ø³Ù¹ Ø§ÛŒÙ…Ø¨ÛŒÚˆÙ†Ú¯Ø² Ø§ÙˆØ± Ø§Ø®ØªÛŒØ§Ø±ÛŒ GPT Ù…Ø§ÚˆÙ„Ø²
- **Docker**: Ù…Ø³ØªÙ‚Ù„ Ù…Ø§Ø­ÙˆÙ„ Ú©Û’ Ù„ÛŒÛ’ Ú©Ù†Ù¹ÛŒÙ†Ø±Ø§Ø¦Ø²ÛŒØ´Ù†
- **Bicep**: Azure ÙˆØ³Ø§Ø¦Ù„ Ú©Û’ Ù„ÛŒÛ’ Infrastructure as Code
- **VS Code**: ØªØ±Ù‚ÛŒØ§ØªÛŒ Ù…Ø§Ø­ÙˆÙ„ MCP Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù† Ú©Û’ Ø³Ø§ØªÚ¾

## ğŸ“š Ù…Ù†Ø¸Ù… Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©ÛŒ Ú¯Ø§Ø¦ÛŒÚˆ: /walkthrough

Ø§Ø³ ØªÚ©Ù†ÛŒÚ©ÛŒ Ø±ÛÙ†Ù…Ø§Ø¦ÛŒ Ú©Û’ Ø¹Ù„Ø§ÙˆÛØŒ Ø§Ø³ Ø±ÛŒÙ¾ÙˆØ²Ù¹Ø±ÛŒ Ù…ÛŒÚº Ø§ÛŒÚ© Ø¬Ø§Ù…Ø¹ **12-Ù…Ø§ÚˆÛŒÙˆÙ„ Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©ÛŒ Ú¯Ø§Ø¦ÛŒÚˆ** Ø´Ø§Ù…Ù„ ÛÛ’ Ø¬Ùˆ `/walkthrough` ÚˆØ§Ø¦Ø±ÛŒÚ©Ù¹Ø±ÛŒ Ù…ÛŒÚº ÙˆØ§Ù‚Ø¹ ÛÛ’Û” ÛŒÛ Ù…Ù†Ø¸Ù… Ø·Ø±ÛŒÙ‚Û Ú©Ø§Ø± Ù¾ÛŒÚ†ÛŒØ¯Û Ø¹Ù…Ù„ Ø¯Ø±Ø¢Ù…Ø¯ Ú©Ùˆ Ù‚Ø§Ø¨Ù„ ÛØ¶Ù… Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù…Ø§ÚˆÛŒÙˆÙ„Ø² Ù…ÛŒÚº ØªÙ‚Ø³ÛŒÙ… Ú©Ø±ØªØ§ ÛÛ’ØŒ Ø¬Ùˆ Ø§Ù† ÚˆÙˆÛŒÙ„Ù¾Ø±Ø² Ú©Û’ Ù„ÛŒÛ’ Ø¨ÛØªØ±ÛŒÙ† ÛÛ’ Ø¬Ùˆ ÛØ± Ø¬Ø²Ùˆ Ú©Ùˆ Ù…Ø±Ø­Ù„Û ÙˆØ§Ø± Ø³Ù…Ø¬Ú¾Ù†Ø§ Ú†Ø§ÛØªÛ’ ÛÛŒÚºÛ”

### Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù…Ø§ÚˆÛŒÙˆÙ„Ø² Ú©Ø§ Ø¬Ø§Ø¦Ø²Û

| Ù…Ø§ÚˆÛŒÙˆÙ„ | Ù…ÙˆØ¶ÙˆØ¹ | ÙÙˆÚ©Ø³ | Ø¯ÙˆØ±Ø§Ù†ÛŒÛ |
|--------|-------|-------|----------|
| **[00-Introduction](walkthrough/00-Introduction/README.md)** | MCP Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø§ØµÙˆÙ„ | Ø¨Ù†ÛŒØ§Ø¯ÛŒ ØªØµÙˆØ±Ø§ØªØŒ Zava Retail Ú©ÛŒØ³ Ø§Ø³Ù¹ÚˆÛŒØŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¬Ø§Ø¦Ø²Û | 30 Ù…Ù†Ù¹ |
| **[01-Architecture](walkthrough/01-Architecture/README.md)** | Ù†Ø¸Ø§Ù… ÚˆÛŒØ²Ø§Ø¦Ù† | ØªÚ©Ù†ÛŒÚ©ÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒØŒ ÚˆÛŒØ²Ø§Ø¦Ù† Ù¾ÛŒÙ¹Ø±Ù†Ø²ØŒ Ø§Ø¬Ø²Ø§Ø¡ Ú©Û’ ØªØ¹Ù„Ù‚Ø§Øª | 45 Ù…Ù†Ù¹ |
| **[02-Security](walkthrough/02-Security/README.md)** | Ø§Ù†Ù¹Ø±Ù¾Ø±Ø§Ø¦Ø² Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ | Azure ØªØµØ¯ÛŒÙ‚ØŒ Row Level SecurityØŒ Ù…Ù„Ù¹ÛŒ Ù¹ÛŒÙ†Ù†Ù¹ Ø¢Ø¦Ø³ÙˆÙ„ÛŒØ´Ù† | 60 Ù…Ù†Ù¹ |
| **[03-Setup](walkthrough/03-Setup/README.md)** | Ù…Ø§Ø­ÙˆÙ„ Ú©ÛŒ ØªØ±ØªÛŒØ¨ | Docker Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù†ØŒ Azure CLIØŒ Ù¾Ø±ÙˆØ¬ÛŒÚ©Ù¹ Ú©ÛŒ Ø´Ø±ÙˆØ¹Ø§Øª | 45 Ù…Ù†Ù¹ |
| **[04-Database](walkthrough/04-Database/README.md)** | ÚˆÛŒÙ¹Ø§ Ù„ÛŒØ¦Ø± | PostgreSQL Ø§Ø³Ú©ÛŒÙ…ÛØŒ pgvector Ø³ÛŒÙ¹ Ø§Ù¾ØŒ RLS Ù¾Ø§Ù„ÛŒØ³ÛŒØ§ÚºØŒ Ù†Ù…ÙˆÙ†Û ÚˆÛŒÙ¹Ø§ | 60 Ù…Ù†Ù¹ |
| **[05-MCP-Server](walkthrough/05-MCP-Server/README.md)** | Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø¹Ù…Ù„ Ø¯Ø±Ø¢Ù…Ø¯ | FastMCP ÙØ±ÛŒÙ… ÙˆØ±Ú©ØŒ ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù†ØŒ Ù¹ÙˆÙ„ ÚˆÛŒÙˆÙ„Ù¾Ù…Ù†Ù¹ | 90 Ù…Ù†Ù¹ |
| **[06-Tools](walkthrough/06-Tools/README.md)** | Ù¹ÙˆÙ„ ÚˆÛŒÙˆÙ„Ù¾Ù…Ù†Ù¹ | MCP Ù¹ÙˆÙ„ ØªØ®Ù„ÛŒÙ‚ØŒ Ú©ÙˆØ¦Ø±ÛŒ Ú©ÛŒ ØªÙˆØ«ÛŒÙ‚ØŒ Ø¨Ø²Ù†Ø³ Ø§Ù†Ù¹ÛŒÙ„ÛŒØ¬Ù†Ø³ | 75 Ù…Ù†Ù¹ |
| **[07-Semantic-Search](walkthrough/07-Semantic-Search/README.md)** | AI Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù† | Azure OpenAI Ø§ÛŒÙ…Ø¨ÛŒÚˆÙ†Ú¯Ø²ØŒ ÙˆÛŒÚ©Ù¹Ø± Ø³Ø±Ú†ØŒ ÛØ§Ø¦Ø¨Ø±Úˆ Ú©ÙˆØ¦Ø±ÛŒØ² | 60 Ù…Ù†Ù¹ |
| **[08-Testing](walkthrough/08-Testing/README.md)** | Ú©ÙˆØ§Ù„Ù¹ÛŒ Ø§Ø´ÙˆØ±Ù†Ø³ | Ù¹ÛŒØ³Ù¹Ù†Ú¯ Ø­Ú©Ù…Øª Ø¹Ù…Ù„ÛŒØŒ ÚˆÛŒØ¨Ú¯Ù†Ú¯ ØªÚ©Ù†ÛŒÚ©ØŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ù¹ÛŒØ³Ù¹Ù†Ú¯ | 75 Ù…Ù†Ù¹ |
| **[09-VS-Code](walkthrough/09-VS-Code/README.md)** | ØªØ±Ù‚ÛŒØ§ØªÛŒ ØªØ¬Ø±Ø¨Û | VS Code Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù†ØŒ AI Ú†ÛŒÙ¹ Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù†ØŒ ÚˆÛŒØ¨Ú¯Ù†Ú¯ ÙˆØ±Ú© ÙÙ„Ùˆ | 45 Ù…Ù†Ù¹ |
| **[10-Deployment](walkthrough/10-Deployment/README.md)** | Ù¾Ø±ÙˆÚˆÚ©Ø´Ù† ØªØ¹ÛŒÙ†Ø§ØªÛŒ | Ú©Ù†Ù¹ÛŒÙ†Ø±Ø§Ø¦Ø²ÛŒØ´Ù†ØŒ Azure Container AppsØŒ CI/CD Ù¾Ø§Ø¦Ù¾ Ù„Ø§Ø¦Ù†Ø² | 90 Ù…Ù†Ù¹ |
| **[11-Monitoring](walkthrough/11-Monitoring/README.md)** | Ù…Ø´Ø§ÛØ¯Û | Application InsightsØŒ Ù…Ù†Ø¸Ù… Ù„Ø§Ú¯Ù†Ú¯ØŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ù…ÛŒÙ¹Ø±Ú©Ø³ | 60 Ù…Ù†Ù¹ |
| **[12-Best-Practices](walkthrough/12-Best-Practices/README.md)** | Ù¾Ø±ÙˆÚˆÚ©Ø´Ù† Ø§ÛŒÚ©Ø³ÛŒÙ„Ù†Ø³ | Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ Ø³Ø®ØªÛŒØŒ Ø§ØµÙ„Ø§Ø­ØŒ Ø§Ù†Ù¹Ø±Ù¾Ø±Ø§Ø¦Ø² Ù¾ÛŒÙ¹Ø±Ù†Ø² | 45 Ù…Ù†Ù¹ |

### Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©ÛŒ Ú¯Ø§Ø¦ÛŒÚˆ Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©ÛŒØ³Û’ Ú©Ø±ÛŒÚº

**ğŸ“– Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù„ÛŒÛ’**: `/walkthrough` Ù…Ø§ÚˆÛŒÙˆÙ„Ø² Ù…Ø±Ø­Ù„Û ÙˆØ§Ø± ÛØ¯Ø§ÛŒØ§Øª ÙØ±Ø§ÛÙ… Ú©Ø±ØªÛ’ ÛÛŒÚº Ø§ÙˆØ± ÛØ± Ø¬Ø²Ùˆ Ú©Ùˆ Ø§Ø³ Ø·Ø±Ø­ ÚˆÛŒØ²Ø§Ø¦Ù† Ú©Ø±Ù†Û’ Ú©ÛŒ ÙˆØ¬ÙˆÛØ§Øª Ú©ÛŒ ÙˆØ¶Ø§Ø­Øª Ú©Ø±ØªÛ’ ÛÛŒÚºÛ” Ù…Ø§ÚˆÛŒÙˆÙ„ 00 Ø³Û’ Ø´Ø±ÙˆØ¹ Ú©Ø±ÛŒÚº Ø§ÙˆØ± ØªØ±ØªÛŒØ¨ ÙˆØ§Ø± Ø¢Ú¯Û’ Ø¨Ú‘Ú¾ÛŒÚºÛ”

**ğŸ”§ Ø¹Ù…Ù„ Ø¯Ø±Ø¢Ù…Ø¯ Ú©Û’ Ù„ÛŒÛ’**: ÛŒÛ Sample_Walkthrough.md ØªÚ©Ù†ÛŒÚ©ÛŒ ØªÙØµÛŒÙ„ Ø§ÙˆØ± Ú©ÙˆÚˆ Ú©ÛŒ ÙˆØ¶Ø§Ø­Øª ÙØ±Ø§ÛÙ… Ú©Ø±ØªØ§ ÛÛ’ ØªØ§Ú©Û ÚˆÙˆÛŒÙ„Ù¾Ø±Ø² Ù…Ú©Ù…Ù„ Ø¹Ù…Ù„ Ø¯Ø±Ø¢Ù…Ø¯ Ú©Ùˆ Ø¬Ù„Ø¯ÛŒ Ø³Ù…Ø¬Ú¾ Ø³Ú©ÛŒÚºÛ”

**ğŸš€ Ù¾Ø±ÙˆÚˆÚ©Ø´Ù† Ú©Û’ Ù„ÛŒÛ’**: Ù…Ø§ÚˆÛŒÙˆÙ„Ø² 02ØŒ 10ØŒ 11ØŒ Ø§ÙˆØ± 12 Ø®Ø§Øµ Ø·ÙˆØ± Ù¾Ø± Ù¾Ø±ÙˆÚˆÚ©Ø´Ù† Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø± ØªØ¹ÛŒÙ†Ø§ØªÛŒØŒ Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒØŒ Ø§ÙˆØ± Ù…Ø´Ø§ÛØ¯Û Ú©Û’ Ù¾ÛÙ„ÙˆØ¤Úº Ù¾Ø± ØªÙˆØ¬Û Ø¯ÛŒØªÛ’ ÛÛŒÚºÛ”

**ğŸ“š Ù…Ú©Ù…Ù„ Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Ø§ Ø±Ø§Ø³ØªÛ**: Ù…Ú©Ù…Ù„ Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©ÛŒ Ú¯Ø§Ø¦ÛŒÚˆ Ú©Û’ Ø¬Ø§Ø¦Ø²Û’ Ú©Û’ Ù„ÛŒÛ’ **[/walkthrough/README.md](walkthrough/README.md)** Ø¯ÛŒÚ©Ú¾ÛŒÚºØŒ Ø¬Ø³ Ù…ÛŒÚº ØªÙØµÛŒÙ„ÛŒ Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù…Ù‚Ø§ØµØ¯ Ø§ÙˆØ± Ø¶Ø±ÙˆØ±ÛŒØ§Øª Ø´Ø§Ù…Ù„ ÛÛŒÚºÛ”

---

## Ù…Ø¹Ù…Ø§Ø±ÛŒ Ú©ÛŒ ØªÙØµÛŒÙ„

### Ø§Ø¹Ù„ÛŒÙ° Ø³Ø·Ø­ÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VS Code AI    â”‚    â”‚   MCP Server    â”‚    â”‚   PostgreSQL    â”‚
â”‚     Client      â”‚â—„â”€â”€â–ºâ”‚  (FastMCP)      â”‚â—„â”€â”€â–ºâ”‚   + pgvector    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Azure OpenAI   â”‚
                       â”‚   Embeddings    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø§Ø¬Ø²Ø§Ø¡

#### 1. **MCP Ø³Ø±ÙˆØ± (`sales_analysis.py`)**
- **FastMCP ÙØ±ÛŒÙ… ÙˆØ±Ú©**: HTTP/SSE Ù¾Ø±ÙˆÙ¹ÙˆÚ©ÙˆÙ„ Ú©Ù…ÛŒÙˆÙ†ÛŒÚ©ÛŒØ´Ù† Ú©Ùˆ ÛÛŒÙ†ÚˆÙ„ Ú©Ø±ØªØ§ ÛÛ’
- **Ù¹ÙˆÙ„ Ø±Ø¬Ø³Ù¹Ø±ÛŒØ´Ù†**: ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ú©ÙˆØ¦Ø±ÛŒ Ø§ÙˆØ± Ø§Ø³Ú©ÛŒÙ…Û Ù¹ÙˆÙ„Ø² Ú©Ùˆ Ø¸Ø§ÛØ± Ú©Ø±ØªØ§ ÛÛ’
- **Ø±ÛŒÚ©ÙˆÛŒØ³Ù¹ Ú©Ø§Ù†Ù¹ÛŒÚ©Ø³Ù¹**: RLS ØµØ§Ø±Ù Ú©ÛŒ Ø´Ù†Ø§Ø®Øª Ú©Ùˆ Ù…Ù†Ø¸Ù… Ú©Ø±ØªØ§ ÛÛ’
- **Ø§ÛŒØ±Ø± ÛÛŒÙ†ÚˆÙ„Ù†Ú¯**: Ù…Ø¶Ø¨ÙˆØ· Ø§ÛŒØ±Ø± Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹ Ø§ÙˆØ± Ù„Ø§Ú¯Ù†Ú¯

#### 2. **ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ù„ÛŒØ¦Ø± (`sales_analysis_postgres.py`)**
- **Ú©Ù†Ú©Ø´Ù† Ù¾ÙˆÙ„Ù†Ú¯**: Ù…ÙˆØ«Ø± asyncpg Ú©Ù†Ú©Ø´Ù† Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹
- **Ø§Ø³Ú©ÛŒÙ…Û Ù¾Ø±ÙˆÙˆØ§Ø¦ÛŒÚˆØ±**: Ù…ØªØ­Ø±Ú© Ù¹ÛŒØ¨Ù„ Ø§Ø³Ú©ÛŒÙ…Û Ø¯Ø±ÛŒØ§ÙØª
- **Ú©ÙˆØ¦Ø±ÛŒ Ø§ÛŒÚ¯Ø²ÛŒÚ©ÛŒÙˆØ´Ù†**: RLS Ú©Û’ Ø³Ø§ØªÚ¾ Ù…Ø­ÙÙˆØ¸ SQL Ø¹Ù…Ù„ Ø¯Ø±Ø¢Ù…Ø¯
- **Ø³ÛŒÙ…ÛŒÙ†Ù¹Ú© Ø³Ø±Ú†**: pgvector Ú©Û’ Ø³Ø§ØªÚ¾ ÙˆÛŒÚ©Ù¹Ø± Ù…Ù…Ø§Ø«Ù„Øª Ø³Ø±Ú†

#### 3. **Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù† Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹ (`config.py`)**
- **Ù…Ø§Ø­ÙˆÙ„ÛŒØ§ØªÛŒ Ù…ØªØºÛŒØ±Ø§Øª**: Ù…Ø±Ú©Ø²ÛŒ Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù† ÛÛŒÙ†ÚˆÙ„Ù†Ú¯
- **Ú©Ù†Ú©Ø´Ù† Ù¾ÛŒØ±Ø§Ù…ÛŒÙ¹Ø±Ø²**: ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø§ÙˆØ± Azure Ø³Ø±ÙˆØ³ Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù†
- **ØªÙˆØ«ÛŒÙ‚**: Ù…Ø·Ù„ÙˆØ¨Û Ù…Ø§Ø­ÙˆÙ„ÛŒØ§ØªÛŒ Ù…ØªØºÛŒØ±Ø§Øª Ú©ÛŒ ØªÙˆØ«ÛŒÙ‚

#### 4. **Ø§Ù†ÙØ±Ø§Ø³Ù¹Ø±Ú©Ú†Ø± (`infra/`)**
- **Bicep Ù¹ÛŒÙ…Ù¾Ù„ÛŒÙ¹Ø³**: Azure ÙˆØ³Ø§Ø¦Ù„ Ú©ÛŒ ÙˆØ¶Ø§Ø­ØªÛŒ ÙØ±Ø§ÛÙ…ÛŒ
- **Ù…Ø§ÚˆÙ„ ØªØ¹ÛŒÙ†Ø§ØªÛŒ**: Ø®ÙˆØ¯Ú©Ø§Ø± AI Ù…Ø§ÚˆÙ„ ØªØ¹ÛŒÙ†Ø§ØªÛŒ
- **Ø±ÙˆÙ„ Ø§Ø³Ø§Ø¦Ù†Ù…Ù†Ù¹Ø³**: Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ Ø±ÙˆÙ„ Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù†

### ÚˆÛŒÙ¹Ø§ ÙÙ„Ùˆ

```
1. VS Code AI Client sends query
2. MCP Server receives request with RLS headers
3. Server extracts user identity and sets context
4. Database queries execute with RLS filtering
5. Results return through MCP protocol
6. AI Client processes structured response
```

---

## Ø­Ù„ Ú©ÛŒ ØªØ¹Ù…ÛŒØ±

### Ù…Ø±Ø­Ù„Û 1: Ù¾Ø±ÙˆØ¬ÛŒÚ©Ù¹ Ø§Ø³Ù¹Ø±Ú©Ú†Ø± Ø³ÛŒÙ¹ Ø§Ù¾

```
project/
â”œâ”€â”€ mcp_server/              # MCP server implementation
â”‚   â”œâ”€â”€ __init__.py         # Package initialization
â”‚   â”œâ”€â”€ sales_analysis.py   # Main MCP server
â”‚   â”œâ”€â”€ sales_analysis_postgres.py  # Database layer
â”‚   â”œâ”€â”€ sales_analysis_text_embeddings.py  # Semantic search
â”‚   â””â”€â”€ config.py           # Configuration management
â”œâ”€â”€ infra/                  # Infrastructure as Code
â”‚   â”œâ”€â”€ main.bicep          # Main deployment template
â”‚   â”œâ”€â”€ foundry.bicep       # Azure AI Foundry setup
â”‚   â”œâ”€â”€ deploy.ps1          # Windows deployment script
â”‚   â””â”€â”€ deploy.sh           # Unix deployment script
â”œâ”€â”€ data/                   # Database backup and initialization
â”œâ”€â”€ docker-init/            # Database initialization scripts
â”œâ”€â”€ .vscode/                # VS Code MCP configuration
â”œâ”€â”€ docker-compose.yml      # Development environment
â”œâ”€â”€ Dockerfile             # MCP server container
â””â”€â”€ requirements.lock.txt   # Python dependencies
```

### Ù…Ø±Ø­Ù„Û 2: Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø¶Ø±ÙˆØ±ÛŒØ§Øª

**Python Ø¶Ø±ÙˆØ±ÛŒØ§Øª:**
```python
# MCP Framework
mcp[server]>=0.5.0
fastmcp>=0.4.0

# Database Integration
asyncpg>=0.29.0
asyncio-rlock>=0.3.0

# Azure Integration
azure-ai-projects>=1.0.0
azure-identity>=1.19.0
azure-monitor-opentelemetry>=1.7.0

# Data Processing
pydantic>=2.9.0
numpy>=1.24.0

# Development
python-dotenv>=1.0.0
```

**Ø³Ø³Ù¹Ù… Ø¶Ø±ÙˆØ±ÛŒØ§Øª:**
- Ú©Ù†Ù¹ÛŒÙ†Ø±Ø§Ø¦Ø²ÛŒØ´Ù† Ú©Û’ Ù„ÛŒÛ’ Docker Desktop
- ØªØ¹ÛŒÙ†Ø§ØªÛŒ Ú©Û’ Ù„ÛŒÛ’ Azure CLI
- PostgreSQL pgvector Ø§ÛŒÚ©Ø³Ù¹ÛŒÙ†Ø´Ù† Ú©Û’ Ø³Ø§ØªÚ¾
- VS Code AI Ø§ÛŒÚ©Ø³Ù¹ÛŒÙ†Ø´Ù†Ø² Ú©Û’ Ø³Ø§ØªÚ¾

### Ù…Ø±Ø­Ù„Û 3: ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø§Ø³Ú©ÛŒÙ…Û ÚˆÛŒØ²Ø§Ø¦Ù†

Ù†Ù…ÙˆÙ†Û Ø§ÛŒÚ© Ø±ÛŒÙ¹ÛŒÙ„ ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªØ§ ÛÛ’ Ø¬Ø³ Ù…ÛŒÚº ÛŒÛ Ú©Ù„ÛŒØ¯ÛŒ Ù¹ÛŒØ¨Ù„Ø² Ø´Ø§Ù…Ù„ ÛÛŒÚº:

```sql
-- Core business entities
retail.stores          -- Store locations and metadata
retail.customers       -- Customer profiles
retail.categories      -- Product categorization
retail.product_types   -- Product type definitions
retail.products        -- Product catalog
retail.orders          -- Customer orders
retail.order_items     -- Order line items
retail.inventory       -- Stock levels

-- Semantic search support
retail.product_description_embeddings  -- Vector embeddings for products
```

**Row Level Security (RLS) Ø¹Ù…Ù„ Ø¯Ø±Ø¢Ù…Ø¯:**
```sql
-- Enable RLS on tables
ALTER TABLE retail.orders ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.customers ENABLE ROW LEVEL SECURITY;

-- Create policies based on store association
CREATE POLICY store_policy ON retail.orders
  FOR ALL TO PUBLIC
  USING (store_id = get_user_store_id());
```

---

## Ø§Ø¬Ø²Ø§Ø¡ Ú©ÛŒ ØªÙØµÛŒÙ„

### MCP Ø³Ø±ÙˆØ± Ú©ÙˆØ± (`sales_analysis.py`)

#### Ù¹ÙˆÙ„ Ø±Ø¬Ø³Ù¹Ø±ÛŒØ´Ù† Ù¾ÛŒÙ¹Ø±Ù†
```python
@mcp.tool()
async def execute_sales_query(
    ctx: Context,
    postgresql_query: Annotated[str, Field(description="A well-formed PostgreSQL query.")],
) -> str:
    """Execute PostgreSQL queries with Row Level Security."""
    rls_user_id = get_rls_user_id(ctx)
    
    try:
        return await db_provider.execute_query(
            postgresql_query, rls_user_id=rls_user_id
        )
    except Exception as e:
        logger.error("Error executing database query: %s", e)
        return f"Error executing database query: {e!s}"
```

**Ø§ÛÙ… Ø®ØµÙˆØµÛŒØ§Øª:**
- **Ù¹Ø§Ø¦Ù¾ Ø§ÛŒÙ†ÙˆÙ¹ÛŒØ´Ù†Ø²**: AI Ú©Ùˆ Ø³Ù…Ø¬Ú¾Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Pydantic ÙÛŒÙ„Úˆ ÙˆØ¶Ø§Ø­ØªÛŒÚº
- **Ú©Ø§Ù†Ù¹ÛŒÚ©Ø³Ù¹ Ø§ÛŒÚ©Ø³Ù¹Ø±ÛŒÚ©Ø´Ù†**: HTTP ÛÛŒÚˆØ±Ø² Ø³Û’ ØµØ§Ø±Ù Ú©ÛŒ Ø´Ù†Ø§Ø®Øª
- **Ø§ÛŒØ±Ø± ÛÛŒÙ†ÚˆÙ„Ù†Ú¯**: Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÛŒ Ù¾ÛŒØºØ§Ù…Ø§Øª Ú©Û’ Ø³Ø§ØªÚ¾ Ø´Ø§Ø¦Ø³ØªÛ Ù†Ø§Ú©Ø§Ù…ÛŒ
- **Ù„Ø§Ú¯Ù†Ú¯**: Ø¬Ø§Ù…Ø¹ Ø¢Ù¾Ø±ÛŒØ´Ù† Ù„Ø§Ú¯Ù†Ú¯

#### Ø±ÛŒÚ©ÙˆÛŒØ³Ù¹ Ú©Ø§Ù†Ù¹ÛŒÚ©Ø³Ù¹ Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹
```python
def get_rls_user_id(ctx: Context) -> str:
    """Extract Row Level Security User ID from request context."""
    rls_user_id = get_header(ctx, "x-rls-user-id")
    if rls_user_id is None:
        # Default to placeholder if not provided
        rls_user_id = "00000000-0000-0000-0000-000000000000"
    return rls_user_id
```

### ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ù„ÛŒØ¦Ø± (`sales_analysis_postgres.py`)

#### Ú©Ù†Ú©Ø´Ù† Ù¾ÙˆÙ„ Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹
```python
class PostgreSQLSchemaProvider:
    async def create_pool(self) -> None:
        """Create connection pool for better resource management."""
        if self.connection_pool is None:
            config_copy = dict(self.postgres_config)
            existing_server_settings = config_copy.pop("server_settings", {})
            
            merged_server_settings = {
                **existing_server_settings,
                "jit": "off",  # Disable JIT to reduce memory usage
                "work_mem": "4MB",  # Limit work memory per query
                "statement_timeout": "30s",  # 30 second statement timeout
            }
            
            self.connection_pool = await asyncpg.create_pool(
                **config_copy,
                min_size=1,
                max_size=3,  # Conservative pool size
                command_timeout=30,
                server_settings=merged_server_settings,
            )
```

**ÚˆÛŒØ²Ø§Ø¦Ù† Ù¾ÛŒÙ¹Ø±Ù†Ø²:**
- **ÙˆØ³Ø§Ø¦Ù„ Ú©Ø§ Ø§Ù†ØªØ¸Ø§Ù…**: Ù¾ÙˆÙ„ Ù„Ø§Ø¦Ù Ø³Ø§Ø¦ÛŒÚ©Ù„ Ú©Ø§ Ù…Ù†Ø§Ø³Ø¨ Ø§Ù†ØªØ¸Ø§Ù…
- **Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©ÛŒ Ø§ØµÙ„Ø§Ø­**: Ø¨ÛØªØ± PostgreSQL Ø³ÛŒÙ¹Ù†Ú¯Ø²
- **Ø§ÛŒØ±Ø± Ø±ÛŒÚ©ÙˆØ±ÛŒ**: Ú©Ù†Ú©Ø´Ù† Ø±ÛŒÙ¹Ø±ÛŒ Ø§ÙˆØ± ÙØ§Ù„ Ø¨ÛŒÚ© Ù„Ø§Ø¬Ú©
- **Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ**: ÛØ± Ú©Ù†Ú©Ø´Ù† Ù¾Ø± RLS Ú©Ø§Ù†Ù¹ÛŒÚ©Ø³Ù¹ Ø³ÛŒÙ¹Ù†Ú¯

#### Ø§Ø³Ú©ÛŒÙ…Û Ø§Ù†Ù¹Ø±ÙˆØ³Ù¾ÛŒÚ©Ø´Ù†
```python
async def get_table_schema(self, table_name: str, rls_user_id: str) -> Dict[str, Any]:
    """Return comprehensive schema information for a table."""
    conn = await self.get_connection()
    
    # Set RLS context
    await conn.execute(
        "SELECT set_config('app.current_rls_user_id', $1, false)", 
        rls_user_id
    )
    
    # Get column information
    columns = await conn.fetch("""
        SELECT column_name, data_type, is_nullable, column_default
        FROM information_schema.columns 
        WHERE table_schema = $1 AND table_name = $2
        ORDER BY ordinal_position
    """, schema_name, table_name)
    
    # Get foreign key relationships
    foreign_keys = await conn.fetch("""
        SELECT kcu.column_name, ccu.table_name AS foreign_table_name
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu ON ...
    """)
```

### Ø³ÛŒÙ…ÛŒÙ†Ù¹Ú© Ø³Ø±Ú† Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù†

#### Ø§ÛŒÙ…Ø¨ÛŒÚˆÙ†Ú¯ Ø¬Ù†Ø±ÛŒØ´Ù†
```python
class SemanticSearchTextEmbedding:
    def generate_query_embedding(self, query: str) -> Optional[List[float]]:
        """Generate embeddings using Azure OpenAI."""
        try:
            response = self.client.embeddings.create(
                input=[query],
                model=self.deployment_name
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error("Embedding generation failed: %s", e)
            return None
```

#### ÙˆÛŒÚ©Ù¹Ø± Ù…Ù…Ø§Ø«Ù„Øª Ø³Ø±Ú†
```python
async def search_products_by_similarity(
    self,
    query_embedding: List[float],
    rls_user_id: str,
    max_rows: int = 20,
    similarity_threshold: float = 30.0,
) -> str:
    """Search products using pgvector cosine similarity."""
    
    # Convert similarity percentage to distance threshold
    distance_threshold = 1.0 - (similarity_threshold / 100.0)
    
    query = f"""
        SELECT p.*, (pde.description_embedding <=> $1::vector) as distance
        FROM {SCHEMA_NAME}.product_description_embeddings pde
        JOIN {SCHEMA_NAME}.products p ON pde.product_id = p.product_id
        WHERE (pde.description_embedding <=> $1::vector) <= $3
        ORDER BY distance
        LIMIT $2
    """
    
    rows = await conn.fetch(query, embedding_str, max_rows, distance_threshold)
```

---

## ØªØ¹ÛŒÙ†Ø§ØªÛŒ Ú¯Ø§Ø¦ÛŒÚˆ

### Azure Ø§Ù†ÙØ±Ø§Ø³Ù¹Ø±Ú©Ú†Ø± ØªØ¹ÛŒÙ†Ø§ØªÛŒ

#### 1. **Bicep Ù¹ÛŒÙ…Ù¾Ù„ÛŒÙ¹ Ø§Ø³Ù¹Ø±Ú©Ú†Ø±**

**Ù…ÛŒÙ† Ù¹ÛŒÙ…Ù¾Ù„ÛŒÙ¹ (`main.bicep`):**
```bicep
targetScope = 'subscription'

// Core parameters
param resourcePrefix string
param location string
param models array = [
  {
    name: 'text-embedding-3-small'
    format: 'OpenAI'
    version: '1'
    capacity: 50
  }
]

// Deploy foundry and project resources
module foundry 'foundry.bicep' = {
  name: 'foundry-account-deployment'
  scope: rg
  params: {
    foundryResourceName: foundryResourceName
    location: location
  }
}

module foundryProject 'foundry-project.bicep' = {
  name: 'foundry-project-deployment'
  scope: rg
  dependsOn: [foundry]
  params: {
    foundryResourceName: foundry.outputs.accountName
    aiProjectName: aiProjectName
  }
}
```

#### 2. **ØªØ¹ÛŒÙ†Ø§ØªÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù†Ø§Ù†Ø§**

**PowerShell ØªØ¹ÛŒÙ†Ø§ØªÛŒ (`deploy.ps1`):**
```powershell
# Generate unique suffix for resources
$UNIQUE_SUFFIX = -join ((97..122) + (48..57) | Get-Random -Count 4 | ForEach-Object { [char]$_ })

# Deploy Azure resources
az deployment sub create `
  --name "$DEPLOYMENT_NAME" `
  --location "$RG_LOCATION" `
  --template-file main.bicep `
  --parameters location="$RG_LOCATION" `
  --parameters resourcePrefix="$RESOURCE_PREFIX" `
  --parameters uniqueSuffix="$UNIQUE_SUFFIX" `
  --parameters models="$modelsJson"

# Create service principal for authentication
$spResult = az ad sp create-for-rbac `
    --name "zava-mcp-server-sp" `
    --role "Cognitive Services OpenAI User" `
    --scopes "/subscriptions/$SubId/resourceGroups/$RESOURCE_GROUP_NAME"

# Generate .env file with configuration
@"
PROJECT_ENDPOINT=$PROJECTS_ENDPOINT
AZURE_OPENAI_ENDPOINT=$AZURE_OPENAI_ENDPOINT
EMBEDDING_MODEL_DEPLOYMENT_NAME="text-embedding-3-small"
AZURE_CLIENT_ID=$clientId
AZURE_CLIENT_SECRET=$clientSecret
AZURE_TENANT_ID=$tenantId
"@ | Out-File -FilePath "../.env"
```

### Ù…Ù‚Ø§Ù…ÛŒ ØªØ±Ù‚ÛŒØ§ØªÛŒ Ø³ÛŒÙ¹ Ø§Ù¾

#### 1. **Docker Compose Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù†**
```yaml
# docker-compose.yml
version: '3.8'
services:
  postgres:
    image: pgvector/pgvector:pg17
    environment:
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
    volumes:
      - ./data:/backup_data:ro
      - ./docker-init:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d zava"]
      interval: 15s
      retries: 5

  mcp_server:
    build: .
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "8000:8000"
    env_file:
      - .env
```

#### 2. **ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø§Ù†ÛŒØ´ÛŒØ§Ù„Ø§Ø¦Ø²ÛŒØ´Ù†**
```bash
# docker-init/init-db.sh
#!/bin/bash
set -e

# Create extensions
psql -v ON_ERROR_STOP=1 --username "$POSTGRES_USER" --dbname "$POSTGRES_DB" <<-EOSQL
    CREATE EXTENSION IF NOT EXISTS vector;
    CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
EOSQL

# Restore database backup
if [ -f /backup_data/zava_retail_2025_07_21_postgres_rls.backup ]; then
    pg_restore --username "$POSTGRES_USER" --dbname "$POSTGRES_DB" \
               --verbose --clean --no-acl --no-owner \
               /backup_data/zava_retail_2025_07_21_postgres_rls.backup
fi
```

---

## Ø­Ù„ Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„

### VS Code Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù†

#### 1. **MCP Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù† (`.vscode/mcp.json`)**
```json
{
    "servers": {
        "zava-sales-analysis-headoffice": {
            "url": "http://127.0.0.1:8000/mcp",
            "type": "http",
            "headers": {"x-rls-user-id": "00000000-0000-0000-0000-000000000000"}
        },
        "zava-sales-analysis-seattle": {
            "url": "http://127.0.0.1:8000/mcp",
            "type": "http", 
            "headers": {"x-rls-user-id": "f47ac10b-58cc-4372-a567-0e02b2c3d479"}
        }
    }
}
```

#### 2. **Ú©ÙˆØ¦Ø±ÛŒ Ù…Ø«Ø§Ù„ÛŒÚº**

**Ø§Ø³Ú©ÛŒÙ…Û Ø¯Ø±ÛŒØ§ÙØª:**
```
AI: #zava What tables are available in the database?
```
*MCP Ø³Ø±ÙˆØ± `get_multiple_table_schemas` Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªØ§ ÛÛ’ ØªØ§Ú©Û Ù¹ÛŒØ¨Ù„ Ø§Ø³Ù¹Ø±Ú©Ú†Ø±Ø² ÙˆØ§Ù¾Ø³ Ú©Ø±Û’*

**Ø³ÛŒÙ„Ø² ØªØ¬Ø²ÛŒÛ:**
```
AI: #zava Show me the top 10 products by revenue last quarter
```
*Ù…Ù†Ø§Ø³Ø¨ Ø¬ÙˆØ§Ø¦Ù†Ø² Ø§ÙˆØ± ØªØ§Ø±ÛŒØ® ÙÙ„Ù¹Ø±Ù†Ú¯ Ú©Û’ Ø³Ø§ØªÚ¾ SQL ØªÛŒØ§Ø± Ú©Ø±ØªØ§ ÛÛ’*

**Ø³ÛŒÙ…ÛŒÙ†Ù¹Ú© Ø³Ø±Ú†:**
```
AI: #zava Find products similar to "waterproof electrical connectors"
```
*Ø§ÛŒÙ…Ø¨ÛŒÚˆÙ†Ú¯Ø² Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªØ§ ÛÛ’ ØªØ§Ú©Û Ø³ÛŒÙ…ÛŒÙ†Ù¹Ú© Ø·ÙˆØ± Ù¾Ø± Ù…Ù…Ø§Ø«Ù„ Ù¾Ø±ÙˆÚˆÚ©Ù¹Ø³ ØªÙ„Ø§Ø´ Ú©Ø±Û’*

**Ù…Ù„Ù¹ÛŒ Ø§Ø³Ù¹ÙˆØ± ØªØ¬Ø²ÛŒÛ:**
```
# Switch to Seattle store manager context
AI: #zava-seattle What are our best-selling categories this month?
```
*RLS ØµØ±Ù Ø³ÛŒØ¦Ù¹Ù„ Ø§Ø³Ù¹ÙˆØ± ÚˆÛŒÙ¹Ø§ ØªÚ© Ø±Ø³Ø§Ø¦ÛŒ Ú©Ùˆ ÛŒÙ‚ÛŒÙ†ÛŒ Ø¨Ù†Ø§ØªØ§ ÛÛ’*

### Ø¬Ø¯ÛŒØ¯ Ú©ÙˆØ¦Ø±ÛŒ Ù¾ÛŒÙ¹Ø±Ù†Ø²

#### 1. **Ù¹Ø§Ø¦Ù… Ø³ÛŒØ±ÛŒØ² ØªØ¬Ø²ÛŒÛ**
```sql
-- Generated by AI through MCP server
SELECT 
    DATE_TRUNC('month', o.order_date) as month,
    SUM(oi.total_amount) as revenue,
    COUNT(DISTINCT o.order_id) as order_count
FROM retail.orders o
JOIN retail.order_items oi ON o.order_id = oi.order_id
WHERE o.order_date >= CURRENT_DATE - INTERVAL '12 months'
GROUP BY DATE_TRUNC('month', o.order_date)
ORDER BY month;
```

#### 2. **Ù¾Ø±ÙˆÚˆÚ©Ù¹ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ø²Ù…Ø±Û Ø¬Ø§Øª Ú©Û’ Ø³Ø§ØªÚ¾**
```sql
-- AI generates complex joins using schema information
SELECT 
    c.category_name,
    pt.type_name,
    COUNT(DISTINCT p.product_id) as product_count,
    SUM(oi.total_amount) as total_revenue,
    AVG(oi.unit_price) as avg_price
FROM retail.products p
JOIN retail.categories c ON p.category_id = c.category_id
JOIN retail.product_types pt ON p.product_type_id = pt.product_type_id
JOIN retail.order_items oi ON p.product_id = oi.product_id
GROUP BY c.category_name, pt.type_name
ORDER BY total_revenue DESC;
```

---

## Ø¬Ø¯ÛŒØ¯ Ø®ØµÙˆØµÛŒØ§Øª

### Row Level Security Ø¹Ù…Ù„ Ø¯Ø±Ø¢Ù…Ø¯

#### 1. **Ù¾Ø§Ù„ÛŒØ³ÛŒ ØªØ®Ù„ÛŒÙ‚**
```sql
-- Store-based access control
CREATE POLICY customer_store_policy ON retail.customers
  FOR ALL TO PUBLIC
  USING (store_id = get_current_store_id());

CREATE POLICY order_store_policy ON retail.orders  
  FOR ALL TO PUBLIC
  USING (store_id = get_current_store_id());

-- Function to get current user's store
CREATE OR REPLACE FUNCTION get_current_store_id()
RETURNS uuid AS $$
BEGIN
  RETURN current_setting('app.current_rls_user_id')::uuid;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

#### 2. **MCP Ø³Ø±ÙˆØ± Ù…ÛŒÚº Ú©Ø§Ù†Ù¹ÛŒÚ©Ø³Ù¹ Ø³ÛŒÙ¹Ù†Ú¯**
```python
async def execute_query(self, sql_query: str, rls_user_id: str) -> str:
    """Execute query with RLS context."""
    conn = await self.get_connection()
    
    # Set RLS context for this connection
    await conn.execute(
        "SELECT set_config('app.current_rls_user_id', $1, false)", 
        rls_user_id
    )
    
    # Execute user query with RLS filtering
    rows = await conn.fetch(sql_query)
    return self.format_results(rows)
```

### Ø³ÛŒÙ…ÛŒÙ†Ù¹Ú© Ø³Ø±Ú† Ú©ÛŒ ØªÙØµÛŒÙ„

#### 1. **Ø§ÛŒÙ…Ø¨ÛŒÚˆÙ†Ú¯ Ù¾Ø§Ø¦Ù¾ Ù„Ø§Ø¦Ù†**
```python
# Generate embeddings for product descriptions
async def generate_product_embeddings():
    products = await get_all_products()
    
    for product in products:
        description = f"{product.name} {product.description} {product.category}"
        embedding = embedding_client.generate_embedding(description)
        
        await store_embedding(product.id, embedding)
```

#### 2. **Ù…Ù…Ø§Ø«Ù„Øª Ø³Ø±Ú† Ú©ÛŒ Ø§ØµÙ„Ø§Ø­**
```sql
-- Create vector index for performance
CREATE INDEX idx_product_embeddings_vector 
ON retail.product_description_embeddings 
USING ivfflat (description_embedding vector_cosine_ops);

-- Optimized similarity query
SELECT p.*, 
       (pde.description_embedding <=> $1::vector) as distance,
       (1 - (pde.description_embedding <=> $1::vector)) * 100 as similarity_percent
FROM retail.product_description_embeddings pde
JOIN retail.products p ON pde.product_id = p.product_id
WHERE (pde.description_embedding <=> $1::vector) < 0.7  -- 30% similarity threshold
ORDER BY distance
LIMIT 20;
```

### Ù…Ø´Ø§ÛØ¯Û Ø§ÙˆØ± Ù†Ú¯Ø±Ø§Ù†ÛŒ

#### 1. **Azure Application Insights Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù†**
```python
# Configure telemetry
from azure.monitor.opentelemetry import configure_azure_monitor
from opentelemetry.instrumentation.starlette import StarletteInstrumentor

# Enable monitoring if configured
if config.applicationinsights_connection_string:
    configure_azure_monitor(
        connection_string=config.applicationinsights_connection_string
    )
    StarletteInstrumentor().instrument_app(mcp.sse_app())
```

#### 2. **Ú©Ø³Ù¹Ù… Ù…ÛŒÙ¹Ø±Ú©Ø³ Ø§ÙˆØ± Ù„Ø§Ú¯Ù†Ú¯**
```python
# Query execution tracking
@contextmanager
async def track_query_execution(query_type: str):
    start_time = time.time()
    try:
        yield
        duration = time.time() - start_time
        logger.info("Query executed", extra={
            "query_type": query_type,
            "duration_ms": duration * 1000,
            "status": "success"
        })
    except Exception as e:
        duration = time.time() - start_time
        logger.error("Query failed", extra={
            "query_type": query_type,
            "duration_ms": duration * 1000,
            "status": "error",
            "error": str(e)
        })
        raise
```

---

## Ù…Ø³Ø§Ø¦Ù„ Ú©Ø§ Ø­Ù„

### Ø¹Ø§Ù… Ù…Ø³Ø§Ø¦Ù„ Ø§ÙˆØ± Ø­Ù„

#### 1. **ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ú©Ù†Ú©Ø´Ù† Ù…Ø³Ø§Ø¦Ù„**
```python
# Connection diagnostics
async def diagnose_connection():
    try:
        pool = await asyncpg.create_pool(**connection_params, min_size=1)
        conn = await pool.acquire()
        result = await conn.fetchval("SELECT 1")
        await pool.release(conn)
        await pool.close()
        return True
    except Exception as e:
        logger.error("Connection failed: %s", e)
        return False
```

**Ø¹Ø§Ù… Ø­Ù„:**
- ØªØµØ¯ÛŒÙ‚ Ú©Ø±ÛŒÚº Ú©Û PostgreSQL Ú†Ù„ Ø±ÛØ§ ÛÛ’: `docker ps`
- `.env` Ù…ÛŒÚº Ú©Ù†Ú©Ø´Ù† Ù¾ÛŒØ±Ø§Ù…ÛŒÙ¹Ø±Ø² Ú†ÛŒÚ© Ú©Ø±ÛŒÚº
- ØªØµØ¯ÛŒÙ‚ Ú©Ø±ÛŒÚº Ú©Û ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ù…ÙˆØ¬ÙˆØ¯ ÛÛ’: `docker exec -it pg17 psql -U postgres -l`
- Ù†ÛŒÙ¹ ÙˆØ±Ú© Ú©Ù†ÛŒÚ©Ù¹ÛŒÙˆÛŒÙ¹ÛŒ Ù¹ÛŒØ³Ù¹ Ú©Ø±ÛŒÚº: `telnet localhost 5432`

#### 2. **RLS Ù¾Ø§Ù„ÛŒØ³ÛŒ Ù…Ø³Ø§Ø¦Ù„**
```sql
-- Debug RLS policies
SELECT schemaname, tablename, policyname, cmd, qual 
FROM pg_policies 
WHERE schemaname = 'retail';

-- Check current RLS setting
SELECT current_setting('app.current_rls_user_id');

-- Temporarily disable RLS for debugging
ALTER TABLE retail.orders DISABLE ROW LEVEL SECURITY;
```

#### 3. **Ø§ÛŒÙ…Ø¨ÛŒÚˆÙ†Ú¯ Ø³Ø±ÙˆØ³ Ù…Ø³Ø§Ø¦Ù„**
```python
# Test embedding generation
async def test_embeddings():
    try:
        test_text = "waterproof electrical connector"
        embedding = embedding_client.generate_embedding(test_text)
        logger.info("Embedding generated successfully: %d dimensions", len(embedding))
        return True
    except Exception as e:
        logger.error("Embedding test failed: %s", e)
        return False
```

### Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©ÛŒ Ø§ØµÙ„Ø§Ø­

#### 1. **Ú©Ù†Ú©Ø´Ù† Ù¾ÙˆÙ„ Ù¹ÛŒÙˆÙ†Ù†Ú¯**
```python
# Optimize for your workload
connection_pool = await asyncpg.create_pool(
    min_size=2,          # Minimum connections
    max_size=10,         # Maximum connections  
    max_inactive_connection_lifetime=300,  # 5 minutes
    command_timeout=30,   # Query timeout
    server_settings={
        "application_name": "mcp-server",
        "work_mem": "4MB",
        "shared_preload_libraries": "pg_stat_statements"
    }
)
```

#### 2. **Ú©ÙˆØ¦Ø±ÛŒ Ú©ÛŒ Ø§ØµÙ„Ø§Ø­**
```sql
-- Add indexes for common query patterns
CREATE INDEX idx_orders_store_date 
ON retail.orders (store_id, order_date);

CREATE INDEX idx_order_items_product 
ON retail.order_items (product_id);

-- Analyze query performance
EXPLAIN (ANALYZE, BUFFERS) 
SELECT ... FROM retail.orders o JOIN retail.order_items oi ...;
```

---

## Ø¨ÛØªØ±ÛŒÙ† Ø·Ø±ÛŒÙ‚Û’

### Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ Ø¨ÛØªØ±ÛŒÙ† Ø·Ø±ÛŒÙ‚Û’

#### 1. **Ù…Ø§Ø­ÙˆÙ„ÛŒØ§ØªÛŒ Ù…ØªØºÛŒØ±Ø§Øª Ú©Ø§ Ø§Ù†ØªØ¸Ø§Ù…**
```bash
# Use strong, unique passwords
POSTGRES_PASSWORD=$(openssl rand -base64 32)

# Rotate service principal credentials regularly
az ad sp credential reset --id $SP_ID --credential-description "Rotated $(date)"

# Use Azure Key Vault in production
az keyvault secret set --vault-name $VAULT_NAME --name "db-password" --value $PASSWORD
```

#### 2. **RLS Ø¹Ù…Ù„ Ø¯Ø±Ø¢Ù…Ø¯ Ú©Û’ Ø±ÛÙ†Ù…Ø§ Ø§ØµÙˆÙ„**
- **ÚˆÛŒÙØ§Ù„Ù¹ ÚˆÛŒÙ†Ø§Ø¦ÛŒ**: Ø³Ø®Øª Ù¾Ø§Ù„ÛŒØ³ÛŒÙˆÚº Ú©Û’ Ø³Ø§ØªÚ¾ Ø´Ø±ÙˆØ¹ Ú©Ø±ÛŒÚº
- **Ø¨Ø§Ù‚Ø§Ø¹Ø¯Û Ø¢ÚˆÙ¹**: Ù¾Ø§Ù„ÛŒØ³ÛŒ Ú©ÛŒ ØªØ§Ø«ÛŒØ± Ú©ÛŒ Ù†Ú¯Ø±Ø§Ù†ÛŒ Ú©Ø±ÛŒÚº
- **Ù…Ú©Ù…Ù„ Ù¹ÛŒØ³Ù¹**: Ø§ÛŒÚ©Ø³ÛŒØ³ Ù¾ÛŒÙ¹Ø±Ù†Ø² Ú©ÛŒ ØªÙˆØ«ÛŒÙ‚ Ú©Ø±ÛŒÚº
- **Ù¾Ø§Ù„ÛŒØ³ÛŒÙˆÚº Ú©ÛŒ Ø¯Ø³ØªØ§ÙˆÛŒØ²Ø§Øª**: ÙˆØ§Ø¶Ø­ Ø¯Ø³ØªØ§ÙˆÛŒØ²Ø§Øª Ø¨Ø±Ù‚Ø±Ø§Ø± Ø±Ú©Ú¾ÛŒÚº

#### 3. **Ù†ÛŒÙ¹ ÙˆØ±Ú© Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ**
```yaml
# Production docker-compose with network isolation
networks:
  internal:
    driver: bridge
    internal: true
  external:
    driver: bridge

services:
  postgres:
    networks:
      - internal
    # No external ports in production
  
  mcp_server:
    networks:
      - internal
      - external
    ports:
      - "127.0.0.1:8000:8000"  # Bind to localhost only
```

### ØªØ±Ù‚ÛŒØ§ØªÛŒ Ø¨ÛØªØ±ÛŒÙ† Ø·Ø±ÛŒÙ‚Û’

#### 1. **Ø§ÛŒØ±Ø± ÛÛŒÙ†ÚˆÙ„Ù†Ú¯ Ù¾ÛŒÙ¹Ø±Ù†Ø²**
```python
# Structured error responses
class MCPError(Exception):
    def __init__(self, message: str, error_type: str = "general"):
        self.message = message
        self.error_type = error_type
        super().__init__(message)

async def safe_execute_query(query: str, rls_user_id: str) -> str:
    try:
        return await db_provider.execute_query(query, rls_user_id)
    except asyncpg.PostgresError as e:
        logger.error("Database error: %s", e)
        return json.dumps({"error": "Database query failed", "type": "database"})
    except Exception as e:
        logger.error("Unexpected error: %s", e)
        return json.dumps({"error": "Internal server error", "type": "server"})
```

#### 2. **Ù¹ÛŒØ³Ù¹Ù†Ú¯ Ø­Ú©Ù…Øª Ø¹Ù…Ù„ÛŒ**
```python
# Unit test example
@pytest.mark.asyncio
async def test_rls_isolation():
    """Test that RLS properly isolates store data."""
    
    # Test Seattle store manager
    seattle_results = await db_provider.execute_query(
        "SELECT COUNT(*) FROM retail.orders",
        rls_user_id="f47ac10b-58cc-4372-a567-0e02b2c3d479"
    )
    
    # Test Redmond store manager  
    redmond_results = await db_provider.execute_query(
        "SELECT COUNT(*) FROM retail.orders", 
        rls_user_id="e7f8a9b0-c1d2-3e4f-5678-90abcdef1234"
    )
    
    # Results should be different due to RLS
    assert seattle_results != redmond_results
```

#### 3. **Ù†Ú¯Ø±Ø§Ù†ÛŒ Ø§ÙˆØ± Ø§Ù„Ø±Ù¹Ø³**
```python
# Custom metrics for monitoring
from prometheus_client import Counter, Histogram, start_http_server

query_counter = Counter('mcp_queries_total', 'Total queries executed', ['query_type'])
query_duration = Histogram('mcp_query_duration_seconds', 'Query execution time')

@query_duration.time()
async def execute_query_with_metrics(query: str, rls_user_id: str):
    query_counter.labels(query_type='sales_analysis').inc()
    return await db_provider.execute_query(query, rls_user_id)
```

### ØªØ¹ÛŒÙ†Ø§ØªÛŒ Ø¨ÛØªØ±ÛŒÙ† Ø·Ø±ÛŒÙ‚Û’

#### 1. **Infrastructure as Code**
```bicep
// Use parameter files for different environments
param environment string = 'dev'
param location string = 'westus2'

// Apply consistent naming conventions
var resourcePrefix = 'zava-mcp-${environment}'
var resourceGroupName = 'rg-${resourcePrefix}-${uniqueSuffix}'

// Use tags for resource management
var commonTags = {
  Environment: environment
  Project: 'zava-mcp-server'
  ManagedBy: 'bicep'
  CreatedDate: utcNow('yyyy-MM-dd')
}
```

#### 2. **CI/CD Ù¾Ø§Ø¦Ù¾ Ù„Ø§Ø¦Ù† Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù†**
```yaml
# Azure DevOps pipeline example
- task: AzureCLI@2
  displayName: 'Deploy Infrastructure'
  inputs:
    azureSubscription: $(azureServiceConnection)
    scriptType: 'bash'
    scriptLocation: 'inlineScript'
    inlineScript: |
      az deployment sub create \
        --name "mcp-server-$(Build.BuildId)" \
        --location $(location) \
        --template-file infra/main.bicep \
        --parameters environment=$(environment)

- task: Docker@2
  displayName: 'Build and Push MCP Server'
  inputs:
    command: 'buildAndPush'
    repository: 'zava-mcp-server'
    tags: '$(Build.BuildId)'
```

---

ÛŒÛ Ø¬Ø§Ù…Ø¹ Ø±ÛÙ†Ù…Ø§Ø¦ÛŒ MCP Ø³Ø±ÙˆØ± Ú©Ùˆ PostgreSQL Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù† Ú©Û’ Ø³Ø§ØªÚ¾ Ø¨Ù†Ø§Ù†Û’ØŒ ØªØ¹ÛŒÙ†Ø§Øª Ú©Ø±Ù†Û’ØŒ Ø§ÙˆØ± Ú†Ù„Ø§Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¨Ù†ÛŒØ§Ø¯ ÙØ±Ø§ÛÙ… Ú©Ø±ØªÛŒ ÛÛ’Û” ÛŒÛØ§Úº Ø¯Ú©Ú¾Ø§Ø¦Û’ Ú¯Ø¦Û’ Ù¾ÛŒÙ¹Ø±Ù†Ø² Ø§ÙˆØ± Ø·Ø±ÛŒÙ‚Û’ Ø¯ÛŒÚ¯Ø± ÚˆÙˆÙ…ÛŒÙ†Ø² Ø§ÙˆØ± Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Û’ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…ÛŒÚº ØªÙˆØ³ÛŒØ¹ Ù¾Ø°ÛŒØ± ÛÛŒÚºØŒ Ø¬Ø¨Ú©Û Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒØŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒØŒ Ø§ÙˆØ± Ø¨Ø±Ù‚Ø±Ø§Ø± Ø±Ú©Ú¾Ù†Û’ Ú©ÛŒ ØµÙ„Ø§Ø­ÛŒØª Ú©Ùˆ Ø¨Ø±Ù‚Ø±Ø§Ø± Ø±Ú©Ú¾ØªÛ’ ÛÛŒÚºÛ”

---

**ÚˆØ³Ú©Ù„ÛŒÙ…Ø±**:  
ÛŒÛ Ø¯Ø³ØªØ§ÙˆÛŒØ² AI ØªØ±Ø¬Ù…Û Ø³Ø±ÙˆØ³ [Co-op Translator](https://github.com/Azure/co-op-translator) Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ ØªØ±Ø¬Ù…Û Ú©ÛŒ Ú¯Ø¦ÛŒ ÛÛ’Û” ÛÙ… Ø¯Ø±Ø³ØªÚ¯ÛŒ Ú©Û’ Ù„ÛŒÛ’ Ú©ÙˆØ´Ø´ Ú©Ø±ØªÛ’ ÛÛŒÚºØŒ Ù„ÛŒÚ©Ù† Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¢Ú¯Ø§Û Ø±ÛÛŒÚº Ú©Û Ø®ÙˆØ¯Ú©Ø§Ø± ØªØ±Ø¬Ù…Û’ Ù…ÛŒÚº ØºÙ„Ø·ÛŒØ§Úº ÛŒØ§ ØºÛŒØ± Ø¯Ø±Ø³ØªÛŒØ§Úº ÛÙˆ Ø³Ú©ØªÛŒ ÛÛŒÚºÛ” Ø§ØµÙ„ Ø¯Ø³ØªØ§ÙˆÛŒØ² Ú©Ùˆ Ø§Ø³ Ú©ÛŒ Ø§ØµÙ„ Ø²Ø¨Ø§Ù† Ù…ÛŒÚº Ù…Ø³ØªÙ†Ø¯ Ø°Ø±ÛŒØ¹Û Ø³Ù…Ø¬Ú¾Ø§ Ø¬Ø§Ù†Ø§ Ú†Ø§ÛÛŒÛ’Û” Ø§ÛÙ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ú©Û’ Ù„ÛŒÛ’ØŒ Ù¾ÛŒØ´Û ÙˆØ± Ø§Ù†Ø³Ø§Ù†ÛŒ ØªØ±Ø¬Ù…Û Ú©ÛŒ Ø³ÙØ§Ø±Ø´ Ú©ÛŒ Ø¬Ø§ØªÛŒ ÛÛ’Û” ÛÙ… Ø§Ø³ ØªØ±Ø¬Ù…Û’ Ú©Û’ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ø³Û’ Ù¾ÛŒØ¯Ø§ ÛÙˆÙ†Û’ ÙˆØ§Ù„ÛŒ Ú©Ø³ÛŒ Ø¨Ú¾ÛŒ ØºÙ„Ø· ÙÛÙ…ÛŒ ÛŒØ§ ØºÙ„Ø· ØªØ´Ø±ÛŒØ­ Ú©Û’ Ø°Ù…Û Ø¯Ø§Ø± Ù†ÛÛŒÚº ÛÛŒÚºÛ”